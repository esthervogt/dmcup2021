{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Author: Esther Vogt\n",
    "# Creation Date: 18.04.2021\n",
    "# Purpose: Get a first understanding of the task & corresponding data\n",
    "\n",
    "# Todo:\n",
    "# - in google docs: language / publishing date matchen @Esther\n",
    "# - sentence embeddings @Estelle\n",
    "\n",
    "# In Progress:\n",
    "# - titel preprocessing: stop word removal / Kommentare wie taschenbuch/editions etc. @Esther\n",
    "\n",
    "# Done:\n",
    "# - create superset @Esther \n",
    "# - pull main topic and sub topic together @Esther"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Imports & Settings\n",
    "########################################################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pycountry\n",
    "from pandas.core.common import flatten\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# allow display of all rows (with scrollbar)\n",
    "pd.set_option(\"display.max_rows\", 10) #pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# determine whether to use calculated language flags or recompute them\n",
    "recompute_lg_flg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# User Input\n",
    "########################################################################################################################\n",
    "\n",
    "# source data file paths\n",
    "transactions_path = '../data/external/transactions.csv'\n",
    "evaluation_path = '../data/external/evaluation.csv'\n",
    "items_path = '../data/external/items.csv'\n",
    "subject_cats_0_path = '../data/external/subject_cats_0.csv'\n",
    "\n",
    "# pre-processed data file paths (incl. language flags)\n",
    "items_path_pp = '../data/processed/items_pp.csv'\n",
    "header_items_path_pp = '../data/processed/header_items_pp.csv'\n",
    "\n",
    "# seaborn color palette\n",
    "palette_blue = \"Blues_d\"\n",
    "dark_blue = \"#011f4b\"\n",
    "middle_blue = \"#005b96\"\n",
    "light_blue = \"#b3cde0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Functions\n",
    "########################################################################################################################\n",
    "\n",
    "def clean_alt_list(list_):\n",
    "#     list_ = list_.replace(', ', ',')\n",
    "    list_ = list_.replace('[', '')\n",
    "    list_ = list_.replace(']', '')\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load & initial pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_df after first pre-processing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "      <th>mt_len</th>\n",
       "      <th>mt_0</th>\n",
       "      <th>mt_cl</th>\n",
       "      <th>st_cl</th>\n",
       "      <th>mt_st_cl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21310</td>\n",
       "      <td>Princess Poppy: The Big Mix Up</td>\n",
       "      <td>Janey Louise Jones</td>\n",
       "      <td>Penguin Random House Children's UK</td>\n",
       "      <td>YFB</td>\n",
       "      <td>[5AH]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>[YFB]</td>\n",
       "      <td>[5AH]</td>\n",
       "      <td>[5AH, YFB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73018</td>\n",
       "      <td>Einfach zeichnen! Step by Step</td>\n",
       "      <td>Wiebke Krabbe</td>\n",
       "      <td>Schwager und Steinlein</td>\n",
       "      <td>AGZ</td>\n",
       "      <td>[5AJ,AGZ,WFA,YBG,YBL,YNA,YPA]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "      <td>[AGZ]</td>\n",
       "      <td>[YBL, 5AJ, WFA, YBG, YNA, YPA, AGZ]</td>\n",
       "      <td>[YBL, 5AJ, WFA, YBG, YNA, YPA, AGZ, AGZ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemID                           title              author  \\\n",
       "0   21310  Princess Poppy: The Big Mix Up  Janey Louise Jones   \n",
       "1   73018  Einfach zeichnen! Step by Step       Wiebke Krabbe   \n",
       "\n",
       "                            publisher main topic  \\\n",
       "0  Penguin Random House Children's UK        YFB   \n",
       "1              Schwager und Steinlein        AGZ   \n",
       "\n",
       "                       subtopics  mt_len mt_0  mt_cl  \\\n",
       "0                          [5AH]     3.0    Y  [YFB]   \n",
       "1  [5AJ,AGZ,WFA,YBG,YBL,YNA,YPA]     3.0    A  [AGZ]   \n",
       "\n",
       "                                 st_cl  \\\n",
       "0                                [5AH]   \n",
       "1  [YBL, 5AJ, WFA, YBG, YNA, YPA, AGZ]   \n",
       "\n",
       "                                   mt_st_cl  \n",
       "0                                [5AH, YFB]  \n",
       "1  [YBL, 5AJ, WFA, YBG, YNA, YPA, AGZ, AGZ]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transactions_df after first pre-processing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>click</th>\n",
       "      <th>basket</th>\n",
       "      <th>order</th>\n",
       "      <th>click_flg</th>\n",
       "      <th>basket_flg</th>\n",
       "      <th>order_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21310</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>73018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sessionID  itemID  click  basket  order  click_flg  basket_flg  order_flg\n",
       "0          0   21310      1       0      0          1           0          0\n",
       "1          1   73018      1       0      0          1           0          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Load Data\n",
    "########################################################################################################################\n",
    "\n",
    "# Load the dmc source data\n",
    "# - clicks/baskets/order over a period of 3M\n",
    "# - rows: one transaction for single item\n",
    "transactions_df = pd.read_csv(transactions_path, delimiter='|', sep='.', encoding='utf-8')\n",
    "# - list of product ids (subset of products from items_df) to be used for prediction\n",
    "evaluation_df = pd.read_csv(evaluation_path, sep='.', encoding='utf-8')\n",
    "items_df = pd.read_csv(items_path, delimiter='|', sep='.', encoding='utf-8')\n",
    "\n",
    "# load category lookup table (manually created)\n",
    "subject_cats_0 = pd.read_csv(subject_cats_0_path, delimiter=';', encoding='utf-8')\n",
    "\n",
    "# Load pre-processed df (incl. language flags)\n",
    "items_df_pp = pd.read_csv(items_path_pp, delimiter=',', encoding='utf-8')\n",
    "\n",
    "########################################################################################################################\n",
    "# Preprocessing for further inspection\n",
    "########################################################################################################################\n",
    "\n",
    "# extract list of base cols\n",
    "initial_cols= list(items_df.columns)\n",
    "\n",
    "# normalization: author col\n",
    "# items_df.loc[items_df['author'] == 'ohne Autor', 'author'] = None\n",
    "\n",
    "# add col: get len of mt string\n",
    "items_df['mt_len'] = items_df['main topic'].str.len()\n",
    "\n",
    "# add col: get first element (top level category) of mt string\n",
    "items_df['mt_0'] = items_df['main topic'].str[0]\n",
    "\n",
    "# add col: main topic as set (and converted back to list)\n",
    "items_df['mt_cl'] = items_df['main topic'].astype(str).apply(lambda x: list(set(clean_alt_list(x).split(','))))\n",
    "\n",
    "# adjust subtopics: set to None if subtopics list is empty\n",
    "items_df['st_cl'] = items_df['subtopics'].astype(str).apply(lambda x: list(set(clean_alt_list(x).split(','))))\n",
    "items_df.loc[items_df['st_cl']=={''}, 'st_cl'] = None\n",
    "\n",
    "# add col: unique combination of main and subtopic\n",
    "items_df['mt_st_cl'] = (items_df['st_cl'] + items_df['mt_cl']) #.apply(set)\n",
    "\n",
    "# add col: get click / basket / order flag\n",
    "transactions_df['click_flg'] = np.where(transactions_df['click'] > 0, 1, 0)\n",
    "transactions_df['basket_flg'] = np.where(transactions_df['basket'] > 0, 1, 0)\n",
    "transactions_df['order_flg'] = np.where(transactions_df['order'] > 0, 1, 0)\n",
    "\n",
    "########################################################################################################################\n",
    "# Inspection of dfs after initial pre-processing\n",
    "########################################################################################################################\n",
    "\n",
    "# show dfs after initial pre-processing\n",
    "print(f'items_df after first pre-processing:')\n",
    "display(items_df.head(2))\n",
    "\n",
    "print(f'transactions_df after first pre-processing:')\n",
    "display(transactions_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** transactions ******\n",
      "shape transactions_df: (365143, 8)\n",
      "cols transactions_df: \n",
      "sessionID     int64\n",
      "itemID        int64\n",
      "click         int64\n",
      "basket        int64\n",
      "order         int64\n",
      "click_flg     int32\n",
      "basket_flg    int32\n",
      "order_flg     int32\n",
      "dtype: object\n",
      "\n",
      "desc transactions_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>click</th>\n",
       "      <th>basket</th>\n",
       "      <th>order</th>\n",
       "      <th>click_flg</th>\n",
       "      <th>basket_flg</th>\n",
       "      <th>order_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>365143.000000</td>\n",
       "      <td>365143.000000</td>\n",
       "      <td>365143.000000</td>\n",
       "      <td>365143.000000</td>\n",
       "      <td>365143.000000</td>\n",
       "      <td>365143.000000</td>\n",
       "      <td>365143.000000</td>\n",
       "      <td>365143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>139586.939175</td>\n",
       "      <td>40051.292307</td>\n",
       "      <td>1.233180</td>\n",
       "      <td>0.141202</td>\n",
       "      <td>0.048403</td>\n",
       "      <td>0.935510</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>0.046300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>80795.207871</td>\n",
       "      <td>22493.347334</td>\n",
       "      <td>1.069996</td>\n",
       "      <td>1.107574</td>\n",
       "      <td>0.268717</td>\n",
       "      <td>0.245624</td>\n",
       "      <td>0.328675</td>\n",
       "      <td>0.210134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>69459.500000</td>\n",
       "      <td>20713.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>139608.000000</td>\n",
       "      <td>40692.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>209750.500000</td>\n",
       "      <td>58916.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>279354.000000</td>\n",
       "      <td>79066.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sessionID         itemID          click         basket  \\\n",
       "count  365143.000000  365143.000000  365143.000000  365143.000000   \n",
       "mean   139586.939175   40051.292307       1.233180       0.141202   \n",
       "std     80795.207871   22493.347334       1.069996       1.107574   \n",
       "min         0.000000       1.000000       0.000000       0.000000   \n",
       "25%     69459.500000   20713.000000       1.000000       0.000000   \n",
       "50%    139608.000000   40692.000000       1.000000       0.000000   \n",
       "75%    209750.500000   58916.000000       1.000000       0.000000   \n",
       "max    279354.000000   79066.000000     118.000000     293.000000   \n",
       "\n",
       "               order      click_flg     basket_flg      order_flg  \n",
       "count  365143.000000  365143.000000  365143.000000  365143.000000  \n",
       "mean        0.048403       0.935510       0.123207       0.046300  \n",
       "std         0.268717       0.245624       0.328675       0.210134  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       1.000000       0.000000       0.000000  \n",
       "50%         0.000000       1.000000       0.000000       0.000000  \n",
       "75%         0.000000       1.000000       0.000000       0.000000  \n",
       "max        28.000000       1.000000       1.000000       1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt unqiue sessions: 271983\n",
      "cnt unqiue items: 24909\n",
      "\n",
      "****** items ******\n",
      "shape items_df: (78030, 9)\n",
      "\n",
      "cols items_df: \n",
      "itemID             int64\n",
      "title             object\n",
      "author            object\n",
      "publisher         object\n",
      "main topic        object\n",
      "subtopics         object\n",
      "mt_len           float64\n",
      "mt_0              object\n",
      "subtopics_str     object\n",
      "dtype: object\n",
      "\n",
      "desc items_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>mt_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78030.000000</td>\n",
       "      <td>77772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39545.062553</td>\n",
       "      <td>2.994355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22825.650252</td>\n",
       "      <td>0.746807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19775.250000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39561.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59306.750000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79067.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             itemID        mt_len\n",
       "count  78030.000000  77772.000000\n",
       "mean   39545.062553      2.994355\n",
       "std    22825.650252      0.746807\n",
       "min        0.000000      1.000000\n",
       "25%    19775.250000      3.000000\n",
       "50%    39561.500000      3.000000\n",
       "75%    59306.750000      3.000000\n",
       "max    79067.000000     10.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Print first summary statistics\n",
    "########################################################################################################################\n",
    "\n",
    "# transactions\n",
    "print('\\n****** transactions ******')\n",
    "print(f'shape transactions_df: {transactions_df.shape}')\n",
    "print(f'cols transactions_df: \\n{transactions_df.dtypes}\\n')\n",
    "print(f'desc transactions_df:')\n",
    "display(transactions_df.describe())\n",
    "\n",
    "# - Get cnt of unique sessions / items\n",
    "print(f'cnt unqiue sessions: {transactions_df[\"sessionID\"].nunique()}') #271,983\n",
    "print(f'cnt unqiue items: {transactions_df[\"itemID\"].nunique()}') #24,909\n",
    "\n",
    "# items\n",
    "print('\\n****** items ******')\n",
    "print(f'shape items_df: {items_df.shape}\\n')\n",
    "print(f'cols items_df: \\n{items_df.dtypes}\\n')\n",
    "print(f'desc items_df:')\n",
    "display(items_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview statistics per relation / attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# count of books per author\n",
    "books_per_author = pd.DataFrame.from_dict(Counter(items_df.loc[:,'author']),\n",
    "                                    orient='index',\n",
    "                                    columns=['book_cnt']).sort_values(by='book_cnt', ascending=False)\n",
    "books_per_author['frac[%]'] = books_per_author['book_cnt'] * 100 / books_per_author['book_cnt'].sum()\n",
    "\n",
    "print(f'# books per author:')\n",
    "display(books_per_author.head(10))\n",
    "\n",
    "print(f'summary statistics of books per author:')\n",
    "display(books_per_author.describe())\n",
    "\n",
    "# distribution of cnt af books among authors\n",
    "books_per_author_cnts = pd.DataFrame(books_per_author['book_cnt'].value_counts().reset_index()).rename(columns={'index': 'book_cnt',\n",
    "                                                                                                                'book_cnt': 'author_cnt'})\n",
    "books_per_author_cnts['author_cnt.cum'] = books_per_author_cnts['author_cnt'].cumsum()\n",
    "books_per_author_cnts['frac[%]'] = books_per_author_cnts['author_cnt'] * 100 / books_per_author_cnts['author_cnt'].sum()\n",
    "books_per_author_cnts['frac.cum[%]'] = books_per_author_cnts['frac[%]'].cumsum()\n",
    "\n",
    "print(f'distribution of books per author:')\n",
    "display(books_per_author_cnts.head(10))\n",
    "sns.set_theme()\n",
    "sns.histplot(books_per_author[books_per_author['book_cnt']<50]['book_cnt'], binwidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# count of books per publisher\n",
    "books_per_publisher = pd.DataFrame.from_dict(Counter(items_df.loc[:,'publisher']),\n",
    "                                    orient='index',\n",
    "                                    columns=['book_cnt']).sort_values(by='book_cnt', ascending=False)\n",
    "books_per_publisher['frac[%]'] = books_per_publisher['book_cnt'] * 100 / books_per_publisher['book_cnt'].sum()\n",
    "\n",
    "print(f'# books per publisher:')\n",
    "display(books_per_publisher.head(10))\n",
    "\n",
    "print(f'summary statistics of books per publisher:')\n",
    "display(books_per_publisher.describe())\n",
    "\n",
    "# distribution of cnt af books among publishers\n",
    "books_per_publisher_cnts = pd.DataFrame(books_per_publisher['book_cnt'].value_counts().reset_index()).rename(columns={'index': 'book_cnt',\n",
    "                                                                                                                'book_cnt': 'publisher_cnt'})\n",
    "books_per_publisher_cnts['publisher_cnt.cum'] = books_per_publisher_cnts['publisher_cnt'].cumsum()\n",
    "books_per_publisher_cnts['frac[%]'] = books_per_publisher_cnts['publisher_cnt'] * 100 / books_per_publisher_cnts['publisher_cnt'].sum()\n",
    "books_per_publisher_cnts['frac.cum[%]'] = books_per_publisher_cnts['frac[%]'].cumsum()\n",
    "\n",
    "print(f'distribution of books per publisher:')\n",
    "display(books_per_publisher_cnts.head(10))\n",
    "sns.set_theme()\n",
    "sns.histplot(books_per_publisher[books_per_publisher['book_cnt']<50]['book_cnt'], binwidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get depth of main topic tree\n",
    "print(f'str len main topics:')\n",
    "display(pd.DataFrame(items_df[\"mt_len\"].describe()))\n",
    "mt_len_hist = sns.histplot(items_df['mt_len']).set_title(f'distribution of len of main topics')\n",
    "\n",
    "# count of books per main topic (=mt) combo\n",
    "books_per_mt = pd.DataFrame.from_dict(Counter(items_df.loc[:,'main topic']),\n",
    "                                    orient='index',\n",
    "                                    columns=['book_cnt']).sort_values(by='book_cnt', ascending=False)\n",
    "books_per_mt['frac[%]'] = books_per_mt['book_cnt'] * 100 / books_per_mt['book_cnt'].sum()\n",
    "\n",
    "# plot mt_0 distribution\n",
    "sns.set_theme()\n",
    "sns.histplot(items_df['mt_0'].astype(str).sort_values())\n",
    "\n",
    "# count of books per first element of mt\n",
    "books_per_mt_0 = pd.DataFrame.from_dict(Counter(items_df.loc[:,'mt_0']),\n",
    "                                    orient='index',\n",
    "                                    columns=['book_cnt']).sort_values(by='book_cnt', ascending=False).reset_index()\n",
    "books_per_mt_0 = books_per_mt_0.rename(columns={'index': 'Notation'})\n",
    "books_per_mt_0['frac[%]'] = books_per_mt_0['book_cnt'] * 100 / books_per_mt_0['book_cnt'].sum()\n",
    "\n",
    "# join with category heading\n",
    "books_per_mt_0 = books_per_mt_0.merge(subject_cats_0, on='Notation', how='left')\n",
    "print(f'top 5 high level cats:')\n",
    "display(books_per_mt_0.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transactions\n",
    "\n",
    "- basket: items that were added to basket but not necessarily bought\n",
    "- order: items that where finally bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# merge transactions with items to get title\n",
    "transactions_df = transactions_df.merge(items_df[['itemID','title']], left_on='itemID', right_on='itemID', how='left')\n",
    "transactions_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnts per sessionID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # get cnt of distinct item clicks per session\n",
    "# unique_clicks_per_session = transactions_df[['sessionID', 'click_flg']].groupby('sessionID')['click_flg'].sum().reset_index().\\\n",
    "#     sort_values(by='click_flg', ascending=False)\n",
    "# unique_clicks_per_session['frac[%]'] = unique_clicks_per_session['click_flg'] * 100 / unique_clicks_per_session['click_flg'].sum()\n",
    "# unique_clicks_per_session = unique_clicks_per_session.rename(columns={'click_flg': '#clicked items unique'})\n",
    "\n",
    "# print(f'clicked items per session:')\n",
    "# display(round(unique_clicks_per_session.head(10),2))\n",
    "\n",
    "# print(f'clicks per item summary stats:')\n",
    "# display(round(unique_clicks_per_session.describe(),2))\n",
    "\n",
    "# sns.boxplot(x=unique_clicks_per_session[\"#clicked items unique\"])\n",
    "# plt.show()\n",
    "\n",
    "# # get cnt of distinctly ordered items per session\n",
    "# orders_per_session = transactions_df[['sessionID', 'order_flg']].groupby('sessionID')['order_flg'].sum().reset_index().\\\n",
    "#     sort_values(by='order_flg', ascending=False).rename(columns={'order_flg': 'order_cnt'})\n",
    "# orders_per_session['frac[%]'] = orders_per_session['order_cnt'] * 100 / orders_per_session['order_cnt'].sum()\n",
    "\n",
    "# print(f'distinct orders per session (binary, w/o qty):')\n",
    "# display(orders_per_session.head(10))\n",
    "\n",
    "# print(f'distinct orders per session summary stats:')\n",
    "# display(orders_per_session.describe())\n",
    "\n",
    "# sns.boxplot(x=orders_per_session[\"order_cnt\"])\n",
    "# plt.show()\n",
    "\n",
    "# # get cnt of distinct order sessions per item\n",
    "# orders_per_item = transactions_df[['itemID', 'order_flg']].groupby('itemID')['order_flg'].sum().reset_index().\\\n",
    "#     sort_values(by='order_flg', ascending=False).rename(columns={'order_flg': 'order_cnt'})\n",
    "# orders_per_item['frac[%]'] = orders_per_item['order_cnt'] * 100 / orders_per_item['order_cnt'].sum()\n",
    "\n",
    "# # print(f'distinct orders per item (binary, w/o qty):')\n",
    "# # display(orders_per_item.head(10))\n",
    "\n",
    "# print(f'distinct orders per item summary stats:')\n",
    "# display(orders_per_item.describe())\n",
    "\n",
    "# get cnt of distinct orders / basket /orders per session\n",
    "interaction_per_session = transactions_df[['sessionID',\n",
    "                                           'click_flg',\n",
    "                                           'basket_flg',\n",
    "                                           'order_flg']].groupby('sessionID').sum().reset_index()\n",
    "print(f'distribution of unique items clicked, added to basket, ordered:')\n",
    "display(round(interaction_per_session[['click_flg','basket_flg','order_flg']].describe(),1).loc[['count','mean','std','25%','50%','75%','max']])\n",
    "\n",
    "# get click to basket to order conversion\n",
    "items_per_basket_order = transactions_df[['itemID',\n",
    "                                          'click_flg',\n",
    "                                          'basket_flg',\n",
    "                                          'order_flg']].groupby(['click_flg',\n",
    "                                                                 'basket_flg',\n",
    "                                                                 'order_flg'])['itemID'].count().reset_index().rename(columns={'itemID': 'item_cnt'})\n",
    "items_per_basket_order['frac[%]'] = items_per_basket_order['item_cnt'] * 100 / items_per_basket_order['item_cnt'].sum()\n",
    "print(f'click to basket to order conversion:')\n",
    "display(round(items_per_basket_order.sort_values(by=['click_flg','basket_flg','order_flg'],ascending=False),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### top interaction items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get top sellers\n",
    "top_interaction_items = transactions_df[['itemID', 'title',\n",
    "                                         'click',\n",
    "                                         'basket',\n",
    "                                         'order']].groupby(['itemID','title']).sum().reset_index().sort_values(by='click')\n",
    "top_clicked_items = top_interaction_items.sort_values(by='click',ascending=False).head(5)\n",
    "top_basket_items = top_interaction_items.sort_values(by='basket',ascending=False).head(5)\n",
    "top_order_items = top_interaction_items.sort_values(by='order',ascending=False).head(5)\n",
    "# display(top_interaction_items.head(10))\n",
    "\n",
    "# generate barplot\n",
    "sns.set_theme()\n",
    "fig, ax = plt.subplots(3,1)\n",
    "plt.tight_layout()\n",
    "sns.barplot(data=top_clicked_items,x='click',y='title',palette=palette_blue, ax=ax[0]).set(xlabel=\"# clicks\",ylabel=\"\")\n",
    "sns.barplot(data=top_basket_items,x='basket',y='title',palette=palette_blue, ax=ax[1]).set(xlabel=\"# added to basket\",ylabel=\"\")\n",
    "sns.barplot(data=top_order_items,x='order',y='title',palette=palette_blue, ax=ax[2]).set(xlabel=\"# orders\",ylabel=\"\")\n",
    "plt.show()\n",
    "\n",
    "# # get cnt of clicks per item\n",
    "# clicks_per_item = transactions_df[['itemID', 'click']].groupby('itemID')['click'].sum().reset_index().\\\n",
    "#     sort_values(by='click', ascending=False).rename(columns={'click': 'click_cnt'})\n",
    "# clicks_per_item['frac[%]'] = clicks_per_item['click_cnt'] * 100 / clicks_per_item['click_cnt'].sum()\n",
    "\n",
    "# print(f'clicks per item:')\n",
    "# display(clicks_per_item.head(10))\n",
    "\n",
    "# print(f'clicks per item summary stats:')\n",
    "# display(clicks_per_item.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "- 9 items w/o publisher:\n",
    "    - could be anything, cannot be imputed\n",
    "    - not such a crucial information to be missing\n",
    "    - thus: no handling\n",
    "- 3240 items w/o author:\n",
    "    - correct author might not be uniquely determinable or there might not even be a senseful author\n",
    "    - thus: no handling\n",
    "- 258 items w/o main topic:\n",
    "    - at least subtopic is given\n",
    "    - only 32 of these also have the author missing\n",
    "- 36,904 items w/o subtopic:\n",
    "    - in all of the cases, a main topic is given\n",
    "    - thus: still enough information available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get cnt of missing values per column\n",
    "missing_values = pd.DataFrame(items_df.isnull().sum()).rename(columns={0: 'cnt'})\n",
    "missing_values['frac[%]'] = missing_values['cnt'] * 100 / len(items_df)\n",
    "print(f'null values per column:')\n",
    "display(round(missing_values.loc[initial_cols + [\"subtopics_str\"]],2))\n",
    "\n",
    "# get cnt of combined null values: sum null values per row and cnt rows with #null > 1\n",
    "print(f'\\n# rows with null values in more than one col: {(items_df[initial_cols + [\"subtopics_str\"]].isnull().sum(axis=1) > 1).sum()}')\n",
    "print(f'\\ndistribution of null values over cols (1=null, 0=not null):')\n",
    "display(pd.DataFrame((items_df[initial_cols + ['subtopics_str']].isnull() * 1).value_counts().reset_index()).rename(columns={0: '#items'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check all items with missing publisher\n",
    "print('all items with missing publisher:')\n",
    "display(items_df[items_df['publisher'].isnull()])\n",
    "\n",
    "# check whether there might be other entries with publisher given\n",
    "missing_publisher_title = items_df[items_df['publisher'].isnull()]['title']\n",
    "print(f'books with same title that appear twice: {(items_df[items_df[\"title\"].isin(missing_publisher_title)].groupby(\"title\")[\"itemID\"].count() > 1).sum()}\\n')\n",
    "\n",
    "# inspect sample with missing publisher\n",
    "# > missing publisher is most likely to be 'TEKTIME' > however: could also be different\n",
    "print('entries for title \"Back to Earth\" with missing publisher for some editions:')\n",
    "display(items_df[items_df['title'].str.contains('Back to Earth')])\n",
    "print('entries for author \"Danilo Clementoni\" with missing publisher for some items:')\n",
    "display(items_df[items_df['author'] == 'Danilo Clementoni'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing author\n",
    "- __problem__:\n",
    "    - there is a lot of items with very generalistic titles like 'Dinosaurier' or 'Die Weihnachtsgeschichte' that do not allow to uniquely determine the correct author\n",
    "    - there might not even be a unique author, like for 'Freundebuch - Einhorn-Paradies - Meine Freunde' or 'Kritzkratz-Spaß Glitzer'\n",
    "    - there might be the same item but several different authors, like for 'Goldilocks and the Three Bears'\n",
    "\n",
    "- __approach__:\n",
    "    - try to not impute author, use other attributes instead, e.g. topic or publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check all items with missing author\n",
    "print('first 10 items with missing author:')\n",
    "display(items_df[items_df['author'].isnull()].head(10))\n",
    "\n",
    "# check whether there might be other entries with author given\n",
    "missing_author_title = items_df[items_df['author'].isnull()]['title']\n",
    "missing_author_cnt_dups = pd.DataFrame(items_df[items_df[\"title\"].isin(missing_author_title)].groupby(\"title\")[\"itemID\"].count())\n",
    "print(f'\\nbooks with same title that appear twice (see df below): {(missing_author_cnt_dups[\"itemID\"] > 1).sum()}')\n",
    "\n",
    "# check whether author can be retried\n",
    "missing_author_dups = missing_author_cnt_dups[missing_author_cnt_dups[\"itemID\"] > 1].reset_index()['title']\n",
    "display(items_df[items_df['title'].isin(missing_author_dups)].sort_values(by='title'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check whether there are items with no topic at all\n",
    "print(f'cnt of items with both, main topic and subtopic == null: {((items_df[\"subtopics_str\"].isnull()) & (items_df[\"main topic\"].isnull())).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check all items with missing topic\n",
    "print('first 10 items with missing topic:')\n",
    "display(items_df[items_df['main topic'].isnull()].head(10))\n",
    "\n",
    "# check whether there might be other entries with topic given\n",
    "missing_topic_title = items_df[items_df['main topic'].isnull()]['title']\n",
    "missing_topic_cnt_dups = pd.DataFrame(items_df[items_df[\"title\"].isin(missing_topic_title)].groupby(\"title\")[\"itemID\"].count())\n",
    "print(f'\\nbooks with same title that appear twice (see df below): {(missing_topic_cnt_dups[\"itemID\"] > 1).sum()}')\n",
    "\n",
    "# check whether topic can be retried\n",
    "missing_topic_dups = missing_topic_cnt_dups[missing_topic_cnt_dups[\"itemID\"] > 1].reset_index()['title']\n",
    "display(items_df[items_df['title'].isin(missing_topic_dups)].sort_values(by='title'))\n",
    "\n",
    "# check cnt of items with main topic and subtopic missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sub\n",
    "- no scalable solution for imputing subtopics\n",
    "- out of the 36,904 missing subtopics, only 2,668 items appear multiple times\n",
    "    - out of these, only 1,574 actually have a duplicate with a subtopic given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check all items with missing topic\n",
    "print('first 10 items with missing topic:')\n",
    "display(items_df[items_df['subtopics_str'].isnull()])\n",
    "\n",
    "# check whether there might be other entries with topic given\n",
    "missing_topic_title = items_df[items_df['subtopics_str'].isnull()]['title']\n",
    "missing_topic_cnt_dups = pd.DataFrame(items_df[items_df[\"title\"].isin(missing_topic_title)].groupby(\"title\")[\"itemID\"].count())\n",
    "print(f'\\nbooks with same title that appear twice (see df below): {(missing_topic_cnt_dups[\"itemID\"] > 1).sum()}')\n",
    "\n",
    "# check whether topic can be retried\n",
    "missing_topic_dups = missing_topic_cnt_dups[(missing_topic_cnt_dups[\"itemID\"] > 1)].reset_index()['title']\n",
    "display(items_df[(items_df['title'].isin(missing_topic_dups)) & (~items_df['subtopics_str'].isnull())].sort_values(by='title'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "\n",
    "__To keep in mind:__\n",
    "1. other relevant attributes are not given, e.g.:\n",
    "    - actual __language__ might not be that of title\n",
    "    - __publication date__ might differ between itemIDs (=Neuauflage)\n",
    "    - title might not be complete (e.g. __subtitle__ missing)\n",
    "        - e.g. '[Ära der Lichtwächter](https://www.amazon.com/s?k=%C3%84ra+der+Lichtw%C3%A4chter&ref=nb_sb_noss)' from 'Klaus Pfrommer' (itemID = (40200,18242)) is collection with differing subtitles \"Die Täuschung\", \"Das Vermächtnis\", \"Die Unschuld\"\n",
    "    - thus: itemID would be unique identifier for actually different items\n",
    "2. __transactions__ might help to differentiate between items and __rank their relevance__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### duplicate entries per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt of duplicate itemID: 0 (0.0%)\n",
      "cnt of duplicate title: 4193 (5.37%)\n",
      "cnt of duplicate author: 10120 (12.97%)\n",
      "cnt of duplicate publisher: 3426 (4.39%)\n",
      "cnt of duplicate main topic: 478 (0.61%)\n",
      "cnt of duplicate subtopics: 2599 (3.33%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "      <th>mt_len</th>\n",
       "      <th>mt_0</th>\n",
       "      <th>subtopics_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33470</th>\n",
       "      <td>44003</td>\n",
       "      <td>(Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators</td>\n",
       "      <td>Michael Häusler</td>\n",
       "      <td>Books on Demand</td>\n",
       "      <td>FM</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34511</th>\n",
       "      <td>12623</td>\n",
       "      <td>(Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators</td>\n",
       "      <td>Michael Häusler</td>\n",
       "      <td>Books on Demand</td>\n",
       "      <td>FL</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30784</th>\n",
       "      <td>69287</td>\n",
       "      <td>13 Kings</td>\n",
       "      <td>V. S. Nesby</td>\n",
       "      <td>Xlibris</td>\n",
       "      <td>FL</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55425</th>\n",
       "      <td>55553</td>\n",
       "      <td>13 Kings</td>\n",
       "      <td>Vs Nesby</td>\n",
       "      <td>Xlibris US</td>\n",
       "      <td>FL</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7605</th>\n",
       "      <td>46714</td>\n",
       "      <td>19 Love Songs</td>\n",
       "      <td>David Levithan</td>\n",
       "      <td>Random House LCC US</td>\n",
       "      <td>YNMD</td>\n",
       "      <td>[5HC,5PS,5PT,YFB,YFM,YFU]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>5HC,5PS,5PT,YFB,YFM,YFU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>70797</td>\n",
       "      <td>Äon</td>\n",
       "      <td>Andreas Brandhorst</td>\n",
       "      <td>Heyne</td>\n",
       "      <td>FHQ</td>\n",
       "      <td>[1DST]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1DST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53131</th>\n",
       "      <td>40200</td>\n",
       "      <td>Ära der Lichtwächter</td>\n",
       "      <td>Klaus Pfrommer</td>\n",
       "      <td>swb media publishing</td>\n",
       "      <td>FMR</td>\n",
       "      <td>[FMR,FMT,FMX]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>FMR,FMT,FMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46735</th>\n",
       "      <td>18242</td>\n",
       "      <td>Ära der Lichtwächter</td>\n",
       "      <td>Klaus Pfrommer</td>\n",
       "      <td>swb media publishing</td>\n",
       "      <td>FMB</td>\n",
       "      <td>[FMB,FMR,FMX]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>FMB,FMR,FMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52956</th>\n",
       "      <td>6755</td>\n",
       "      <td>Éveil</td>\n",
       "      <td>Aurora Clerc</td>\n",
       "      <td>Books on Demand</td>\n",
       "      <td>FMB</td>\n",
       "      <td>[5AX,FMH,FT,3KLF]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5AX,FMH,FT,3KLF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52926</th>\n",
       "      <td>1078</td>\n",
       "      <td>Éveil</td>\n",
       "      <td>Aurora Clerc</td>\n",
       "      <td>Books on Demand</td>\n",
       "      <td>FMB</td>\n",
       "      <td>[5AX,FMH,FT]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5AX,FMH,FT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10095 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemID                                                          title  \\\n",
       "33470   44003  (Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators   \n",
       "34511   12623  (Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators   \n",
       "30784   69287                                                       13 Kings   \n",
       "55425   55553                                                       13 Kings   \n",
       "7605    46714                                                  19 Love Songs   \n",
       "...       ...                                                            ...   \n",
       "7000    70797                                                            Äon   \n",
       "53131   40200                                           Ära der Lichtwächter   \n",
       "46735   18242                                           Ära der Lichtwächter   \n",
       "52956    6755                                                          Éveil   \n",
       "52926    1078                                                          Éveil   \n",
       "\n",
       "                   author             publisher main topic  \\\n",
       "33470     Michael Häusler       Books on Demand         FM   \n",
       "34511     Michael Häusler       Books on Demand         FL   \n",
       "30784         V. S. Nesby               Xlibris         FL   \n",
       "55425            Vs Nesby            Xlibris US         FL   \n",
       "7605       David Levithan   Random House LCC US       YNMD   \n",
       "...                   ...                   ...        ...   \n",
       "7000   Andreas Brandhorst                 Heyne        FHQ   \n",
       "53131      Klaus Pfrommer  swb media publishing        FMR   \n",
       "46735      Klaus Pfrommer  swb media publishing        FMB   \n",
       "52956        Aurora Clerc       Books on Demand        FMB   \n",
       "52926        Aurora Clerc       Books on Demand        FMB   \n",
       "\n",
       "                       subtopics  mt_len mt_0            subtopics_str  \n",
       "33470                         []     2.0    F                     None  \n",
       "34511                         []     2.0    F                     None  \n",
       "30784                         []     2.0    F                     None  \n",
       "55425                         []     2.0    F                     None  \n",
       "7605   [5HC,5PS,5PT,YFB,YFM,YFU]     4.0    Y  5HC,5PS,5PT,YFB,YFM,YFU  \n",
       "...                          ...     ...  ...                      ...  \n",
       "7000                      [1DST]     3.0    F                     1DST  \n",
       "53131              [FMR,FMT,FMX]     3.0    F              FMR,FMT,FMX  \n",
       "46735              [FMB,FMR,FMX]     3.0    F              FMB,FMR,FMX  \n",
       "52956          [5AX,FMH,FT,3KLF]     3.0    F          5AX,FMH,FT,3KLF  \n",
       "52926               [5AX,FMH,FT]     3.0    F               5AX,FMH,FT  \n",
       "\n",
       "[10095 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cnt column-wise duplication\n",
    "sc_cnt = 1\n",
    "total = len(items_df)\n",
    "for col in initial_cols:\n",
    "    dup_cnts = (items_df[col].value_counts() > 1).sum()\n",
    "    print(f'cnt of duplicate {col}: {dup_cnts} ({round(dup_cnts*100/total,2)}%)')\n",
    "\n",
    "# inspect title duplicates\n",
    "title_cnts = (items_df[\"title\"].value_counts().reset_index())\n",
    "title_dups_lst = title_cnts[title_cnts[\"title\"]>1][\"index\"]\n",
    "items_df[(items_df[\"title\"].isin(title_dups_lst))].sort_values(by=\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### everything identical except of single column\n",
    "- only cases for duplicated items with same attributes but different itemID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "col_list = initial_cols #['itemID']\n",
    "for col in col_list:\n",
    "\n",
    "    # check all cols except of current one\n",
    "    col_list_lim = [c for c in items_df.columns if c != col]\n",
    "    #print(f'{col}: {col_list_lim}')\n",
    "\n",
    "    # compute duplicate cnt\n",
    "    dup = pd.DataFrame(items_df.groupby(col_list_lim)[col].count().reset_index())\n",
    "    print(f'everything identical except of {col} = {(dup[col] > 1).sum()}')\n",
    "    #display(dup[dup[col] > 1].sort_values(by=col))\n",
    "    #display(dup.sort_values(by=col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# deep dive: everything identical except of ID\n",
    "print(f'sample entry for sc1: everything identical except of itemID')\n",
    "display(items_df[items_df['title']=='Reisestipendien'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [DEV] Outlier Detection\n",
    "- only for __transactions__: remove transactions with suspiciously high #of clicks/basket/order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [DEV] String normalization\n",
    "\n",
    "__Applied:__\n",
    "1. conversion to lowercase, e.g. publisher = 'TEKTIME' or 'Tektime' to 'tektime'\n",
    "2. removal of leading special characters, e.g. \",william shakespeare\"\n",
    "3. conversion of unicode characters (ä,ö,ü)\n",
    "\n",
    "__No fix yet:__\n",
    "1. author = 'V. S. Nesby' and 'Vs Nesby' -> approach: no test for equality but similarity / remove dots?\n",
    "2. weird entries\n",
    "    - author: der Authhhhor\n",
    "    - diverse Autoren, Autoren\n",
    "3. unicode characters like (à,é,è,°o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generate copy of original df\n",
    "items_df_cl = items_df.copy()\n",
    "display(items_df_cl.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Functions -> move to beginning of script\n",
    "\n",
    "def remove_special_characters(list_):\n",
    "    list_ = re.sub(r'®','',list_)\n",
    "    list_ = re.sub(r'^\\W+', r'', list_) #removes leading non-alphanumerics, e.g. \",william shakespeare\"\n",
    "    return list_\n",
    "\n",
    "def remove_nontitle_substrings(list_):\n",
    "\n",
    "    # type of book\n",
    "    for book_type in ['taschenbuch','hardcover']:\n",
    "        list_ = re.sub(f'\\(.*{book_type}.*\\)?','',list_) #remove all content within brackets\n",
    "        list_ = re.sub(f'-\\s*(\\w*\\s*){book_type}.*','',list_)\n",
    "        list_ = re.sub(f':.*{book_type}.*','',list_)\n",
    "        list_ = re.sub(f'(.*{book_type}[\\w\\d\\s]*):','',list_)\n",
    "        list_ = re.sub(f'[(special)(book)(edition)\\s*]*{book_type}\\s*[(special)(book)(edition)\\s*]*','',list_)\n",
    "        list_ = re.sub(f'{book_type}','',list_)\n",
    "\n",
    "#     list_ = re.sub(r'\\(.*hardcover.*\\)?','',list_)\n",
    "#     list_ = re.sub(r':.*hardcover.*','',list_)\n",
    "\n",
    "    return list_\n",
    "\n",
    "def convert_umlaute(list_):\n",
    "    \"\"\"\n",
    "    converts ä > ae, ö > oe, etc.\n",
    "    \"\"\"\n",
    "    # convert umlaute\n",
    "#     chars = {'ö':'oe','ä':'ae','ü':'ue'} # usw.\n",
    "#     for char in chars:\n",
    "#         items_df_cl[\"author_cl\"] = items_df_cl[\"author_cl\"].apply(lambda s: s.replace(char, chars[char]) if type(s) == str else s)\n",
    "\n",
    "#     # test sample after normalization\n",
    "#     items_df_cl[items_df_cl[\"author_cl\"].str.contains('schlueter')].head(10)\n",
    "    return list_\n",
    "    \n",
    "def insert_dot_after_single_chars(list_):\n",
    "    list_ = re.sub(r'([A-Z])\\.?(?![a-z])\\s*', r'\\g<1>. ', list_)\n",
    "    return list_\n",
    "    \n",
    "\n",
    "# generate titles df (with comparison column for original and cleaned title)\n",
    "titles_df = pd.DataFrame(items_df_cl[\"title\"].unique()).rename(columns={0: \"title\"})\n",
    "titles_df['title_cl'] = titles_df['title']\n",
    "\n",
    "print(f'#unique titles (before preprocessing): {titles_df[\"title\"].nunique()} / {len(titles_df)}')\n",
    "\n",
    "# convert all strings to lowercase\n",
    "titles_df = titles_df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "display(titles_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print cnt of items including special terms\n",
    "print(f'#items with title including:')\n",
    "for entry in ['hardcover','taschenbuch']:\n",
    "    cnt = titles_df[\"title\"].str.contains(f'{entry}').sum()\n",
    "    print(f'\\t{entry}: {cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# inspect matches for specific terms/patterns\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "p = re.compile('\\(.*\\)')\n",
    "matches = titles_df[\"title\"].apply(lambda s: p.findall(s))\n",
    "matches = pd.DataFrame(set(flatten([x for x in matches if x])))\n",
    "matches.head()\n",
    "\n",
    "# (1) -> elfengeist (1)\n",
    "# (dt. ausgabe)\n",
    "# the dark artifices box set (3 bände im schuber)\n",
    "# star wars(tm) - schülerin der dunklen seite\n",
    "# (sammelband) / (filmausgabe)\n",
    "# (neuauflage) / (sonderausgabe)\n",
    "# (roman) / (light novel)\n",
    "# (großdruck)\n",
    "# (gift edition) / (signed limited edition)\n",
    "# (manga)\n",
    "# (1-3 jahre)\n",
    "# (greek edition) / (german edition) / (greek book for kids) -> additional column with language tag extracted?\n",
    "# (spanish language edition of the things m -> check if error during reading in\n",
    "# (hardback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# search for specific entry\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "search_entry = '\\(.*\\)'\n",
    "display(titles_df.loc[titles_df['title'].str.contains(f'{search_entry}'), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Testing of removal\n",
    "book_type = 'hardcover'\n",
    "for book in [\"no trail behind me, special edition hardcover\", \"no trail behind me, hardcover special edition\"]:\n",
    "    print(re.sub(f'[(special)(book)(edition)\\s*]*{book_type}\\s*[(special)(book)(edition)\\s*]*','',book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# apply pre-processing\n",
    "pd.set_option(\"display.max_rows\", 5)\n",
    "\n",
    "# clean strings\n",
    "titles_df['title_cl'] = titles_df['title_cl'].astype(str).apply(remove_special_characters)\n",
    "titles_df['title_cl'] = titles_df['title_cl'].apply(remove_nontitle_substrings)\n",
    "\n",
    "# test: remove_special_characters\n",
    "# display(titles_df.loc[titles_df['title_cl'].str.contains('ninjago'), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test effect of normalization\n",
    "\n",
    "# inspect overall df\n",
    "items_df_cl[~items_df_cl['author'].isna()].sort_values(by='author').head(100)[['itemID','title', 'author','author_cl']]\n",
    "\n",
    "# check items affected by normalization\n",
    "author_cl_unique_author = items_df_cl.groupby(\"author_cl\")[\"author\"].nunique()\n",
    "print(f'cnt of authors that could be matched due to normalization: {(author_cl_unique_author > 1).sum()}')\n",
    "items_df_cl[items_df_cl['author_cl'].isin(author_cl_unique_author[author_cl_unique_author > 1].reset_index()['author_cl'])].sort_values(by='author_cl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [DEV] Unify main and subtopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [DEV] Header-Set Generation\n",
    "\n",
    "__Approach:__\n",
    "1. __[done]__ Generate new header-set with new IDs to unify same books that appear multiple times in the items and transactions table\n",
    "    a. generate new IDs\n",
    "    b. unify information\n",
    "2. Pull data on header level from external sources (e.g. google doc incl. publication date and language flag)\n",
    "3. __[done]__ Replace the subset IDs in transactions table by superset IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_header_set(items_df):\n",
    "    \"\"\"\n",
    "    generates header set of items that combines attributes of several items with same title that e.g. only differ in itemID\n",
    "    or other attributes\n",
    "    > headerID can be used to replace itemID in transactions_df\n",
    "    \"\"\"\n",
    "    # generate header attribute sets from sub-items -> important: generate sets to prevent duplication \n",
    "    header_items_author_df = items_df['author'].groupby([items_df.title]).apply(set).reset_index()\n",
    "    header_items_publisher_df = items_df['publisher'].groupby([items_df.title]).apply(set).reset_index()\n",
    "    header_items_mtst_df = items_df['mt_st_cl'].groupby([items_df.title]).apply(sum).apply(set).reset_index() # get unique list of topics\n",
    "\n",
    "    # compile the list of dataframes you want to merge\n",
    "    header_items_df_lst = [header_items_author_df, header_items_publisher_df, header_items_mtst_df]\n",
    "\n",
    "    # merge all attributes\n",
    "    header_items_df = reduce(lambda left,right: pd.merge(left,right,on=['title'],\n",
    "                                                how='outer'), header_items_df_lst)\n",
    "\n",
    "    # generate new header index\n",
    "    header_items_df = header_items_df.reset_index().rename(columns={'index':'headerID'})\n",
    "\n",
    "#     # result inspection\n",
    "#     print(f'shape of items_df: {items_df.shape}')\n",
    "#     print(f'shape of header_items_df: {header_items_df.shape}')\n",
    "\n",
    "#     print(f'\\ncnt of duplicate \"title\" in header_df: {(header_items_df[\"title\"].value_counts() > 1).sum()} ({round(dup_cnts*100/len(header_items_df),2)}%)')\n",
    "\n",
    "#     print(f'\\nconverted df:')\n",
    "#     display(header_items_df[header_items_df['title'].isin(['(Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators',\n",
    "#                                                    '13 Kings',\n",
    "#                                                    'Ära der Lichtwächter'])].head(5))\n",
    "\n",
    "#     print(f'\\noriginal df:')\n",
    "#     display(items_df[items_df['title'].isin(['(Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators',\n",
    "#                                                    '13 Kings',\n",
    "#                                                    'Ära der Lichtwächter'])].head(5))\n",
    "\n",
    "    return header_items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of items_df: (78030, 11)\n",
      "shape of header_items_df: (72128, 5)\n",
      "\n",
      "cnt of duplicate \"title\" in header_df: 0 (0.0%)\n",
      "\n",
      "original df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "      <th>mt_len</th>\n",
       "      <th>mt_0</th>\n",
       "      <th>mt_cl</th>\n",
       "      <th>st_cl</th>\n",
       "      <th>mt_st_cl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30784</th>\n",
       "      <td>69287</td>\n",
       "      <td>13 Kings</td>\n",
       "      <td>V. S. Nesby</td>\n",
       "      <td>Xlibris</td>\n",
       "      <td>FL</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>[FL]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[, FL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33470</th>\n",
       "      <td>44003</td>\n",
       "      <td>(Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators</td>\n",
       "      <td>Michael Häusler</td>\n",
       "      <td>Books on Demand</td>\n",
       "      <td>FM</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>[FM]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[, FM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34511</th>\n",
       "      <td>12623</td>\n",
       "      <td>(Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators</td>\n",
       "      <td>Michael Häusler</td>\n",
       "      <td>Books on Demand</td>\n",
       "      <td>FL</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>[FL]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[, FL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46735</th>\n",
       "      <td>18242</td>\n",
       "      <td>Ära der Lichtwächter</td>\n",
       "      <td>Klaus Pfrommer</td>\n",
       "      <td>swb media publishing</td>\n",
       "      <td>FMB</td>\n",
       "      <td>[FMB,FMR,FMX]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>[FMB]</td>\n",
       "      <td>[FMB, FMX, FMR]</td>\n",
       "      <td>[FMB, FMX, FMR, FMB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53131</th>\n",
       "      <td>40200</td>\n",
       "      <td>Ära der Lichtwächter</td>\n",
       "      <td>Klaus Pfrommer</td>\n",
       "      <td>swb media publishing</td>\n",
       "      <td>FMR</td>\n",
       "      <td>[FMR,FMT,FMX]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>[FMR]</td>\n",
       "      <td>[FMT, FMX, FMR]</td>\n",
       "      <td>[FMT, FMX, FMR, FMR]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemID                                                          title  \\\n",
       "30784   69287                                                       13 Kings   \n",
       "33470   44003  (Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators   \n",
       "34511   12623  (Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators   \n",
       "46735   18242                                           Ära der Lichtwächter   \n",
       "53131   40200                                           Ära der Lichtwächter   \n",
       "\n",
       "                author             publisher main topic      subtopics  \\\n",
       "30784      V. S. Nesby               Xlibris         FL             []   \n",
       "33470  Michael Häusler       Books on Demand         FM             []   \n",
       "34511  Michael Häusler       Books on Demand         FL             []   \n",
       "46735   Klaus Pfrommer  swb media publishing        FMB  [FMB,FMR,FMX]   \n",
       "53131   Klaus Pfrommer  swb media publishing        FMR  [FMR,FMT,FMX]   \n",
       "\n",
       "       mt_len mt_0  mt_cl            st_cl              mt_st_cl  \n",
       "30784     2.0    F   [FL]               []                [, FL]  \n",
       "33470     2.0    F   [FM]               []                [, FM]  \n",
       "34511     2.0    F   [FL]               []                [, FL]  \n",
       "46735     3.0    F  [FMB]  [FMB, FMX, FMR]  [FMB, FMX, FMR, FMB]  \n",
       "53131     3.0    F  [FMR]  [FMT, FMX, FMR]  [FMT, FMX, FMR, FMR]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "converted df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headerID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>mt_st_cl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>(Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators</td>\n",
       "      <td>{Michael Häusler}</td>\n",
       "      <td>{Books on Demand}</td>\n",
       "      <td>{, FM, FL}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>13 Kings</td>\n",
       "      <td>{Vs Nesby, V. S. Nesby}</td>\n",
       "      <td>{Xlibris, Xlibris US}</td>\n",
       "      <td>{, FL}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72083</th>\n",
       "      <td>72083</td>\n",
       "      <td>Ära der Lichtwächter</td>\n",
       "      <td>{Klaus Pfrommer}</td>\n",
       "      <td>{swb media publishing}</td>\n",
       "      <td>{FMT, FMB, FMX, FMR}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       headerID  \\\n",
       "68           68   \n",
       "195         195   \n",
       "72083     72083   \n",
       "\n",
       "                                                               title  \\\n",
       "68     (Heli-)opolis - Der verhängnisvolle Plan des Weltkoordinators   \n",
       "195                                                         13 Kings   \n",
       "72083                                           Ära der Lichtwächter   \n",
       "\n",
       "                        author               publisher              mt_st_cl  \n",
       "68           {Michael Häusler}       {Books on Demand}            {, FM, FL}  \n",
       "195    {Vs Nesby, V. S. Nesby}   {Xlibris, Xlibris US}                {, FL}  \n",
       "72083         {Klaus Pfrommer}  {swb media publishing}  {FMT, FMB, FMX, FMR}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "      <th>mt_len</th>\n",
       "      <th>mt_0</th>\n",
       "      <th>mt_cl</th>\n",
       "      <th>st_cl</th>\n",
       "      <th>mt_st_cl</th>\n",
       "      <th>headerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21310</td>\n",
       "      <td>Princess Poppy: The Big Mix Up</td>\n",
       "      <td>Janey Louise Jones</td>\n",
       "      <td>Penguin Random House Children's UK</td>\n",
       "      <td>YFB</td>\n",
       "      <td>[5AH]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>[YFB]</td>\n",
       "      <td>[5AH]</td>\n",
       "      <td>[5AH, YFB]</td>\n",
       "      <td>45233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73018</td>\n",
       "      <td>Einfach zeichnen! Step by Step</td>\n",
       "      <td>Wiebke Krabbe</td>\n",
       "      <td>Schwager und Steinlein</td>\n",
       "      <td>AGZ</td>\n",
       "      <td>[5AJ,AGZ,WFA,YBG,YBL,YNA,YPA]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "      <td>[AGZ]</td>\n",
       "      <td>[YBL, 5AJ, WFA, YBG, YNA, YPA, AGZ]</td>\n",
       "      <td>[YBL, 5AJ, WFA, YBG, YNA, YPA, AGZ, AGZ]</td>\n",
       "      <td>18841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19194</td>\n",
       "      <td>Red Queen 1</td>\n",
       "      <td>Victoria Aveyard</td>\n",
       "      <td>Orion Publishing Group</td>\n",
       "      <td>YFH</td>\n",
       "      <td>[5AP,FBA]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>[YFH]</td>\n",
       "      <td>[FBA, 5AP]</td>\n",
       "      <td>[FBA, 5AP, YFH]</td>\n",
       "      <td>46439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40250</td>\n",
       "      <td>Meine Kindergarten-Freunde (Pirat)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ars Edition GmbH</td>\n",
       "      <td>YB</td>\n",
       "      <td>[5AC,5AD,YBG,YBL,YF]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>[YB]</td>\n",
       "      <td>[YBL, 5AD, 5AC, YBG, YF]</td>\n",
       "      <td>[YBL, 5AD, 5AC, YBG, YF, YB]</td>\n",
       "      <td>38287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46107</td>\n",
       "      <td>Mein großes Schablonen-Buch - Wilde Tiere</td>\n",
       "      <td>Elizabeth Golding</td>\n",
       "      <td>Edition Michael Fischer</td>\n",
       "      <td>WFTM</td>\n",
       "      <td>[WD,WFTM,YBG,YBL,YBLD,YBLN1]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>W</td>\n",
       "      <td>[WFTM]</td>\n",
       "      <td>[YBL, YBLN1, YBG, WFTM, WD, YBLD]</td>\n",
       "      <td>[YBL, YBLN1, YBG, WFTM, WD, YBLD, WFTM]</td>\n",
       "      <td>38114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemID                                      title              author  \\\n",
       "0   21310             Princess Poppy: The Big Mix Up  Janey Louise Jones   \n",
       "1   73018             Einfach zeichnen! Step by Step       Wiebke Krabbe   \n",
       "2   19194                                Red Queen 1    Victoria Aveyard   \n",
       "3   40250         Meine Kindergarten-Freunde (Pirat)                 NaN   \n",
       "4   46107  Mein großes Schablonen-Buch - Wilde Tiere   Elizabeth Golding   \n",
       "\n",
       "                            publisher main topic  \\\n",
       "0  Penguin Random House Children's UK        YFB   \n",
       "1              Schwager und Steinlein        AGZ   \n",
       "2              Orion Publishing Group        YFH   \n",
       "3                    Ars Edition GmbH         YB   \n",
       "4             Edition Michael Fischer       WFTM   \n",
       "\n",
       "                       subtopics  mt_len mt_0   mt_cl  \\\n",
       "0                          [5AH]     3.0    Y   [YFB]   \n",
       "1  [5AJ,AGZ,WFA,YBG,YBL,YNA,YPA]     3.0    A   [AGZ]   \n",
       "2                      [5AP,FBA]     3.0    Y   [YFH]   \n",
       "3           [5AC,5AD,YBG,YBL,YF]     2.0    Y    [YB]   \n",
       "4   [WD,WFTM,YBG,YBL,YBLD,YBLN1]     4.0    W  [WFTM]   \n",
       "\n",
       "                                 st_cl  \\\n",
       "0                                [5AH]   \n",
       "1  [YBL, 5AJ, WFA, YBG, YNA, YPA, AGZ]   \n",
       "2                           [FBA, 5AP]   \n",
       "3             [YBL, 5AD, 5AC, YBG, YF]   \n",
       "4    [YBL, YBLN1, YBG, WFTM, WD, YBLD]   \n",
       "\n",
       "                                   mt_st_cl  headerID  \n",
       "0                                [5AH, YFB]     45233  \n",
       "1  [YBL, 5AJ, WFA, YBG, YNA, YPA, AGZ, AGZ]     18841  \n",
       "2                           [FBA, 5AP, YFH]     46439  \n",
       "3              [YBL, 5AD, 5AC, YBG, YF, YB]     38287  \n",
       "4   [YBL, YBLN1, YBG, WFTM, WD, YBLD, WFTM]     38114  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing headerIDs in items_df: 0\n"
     ]
    }
   ],
   "source": [
    "# generate header set with unique ids for \"super-items\"\n",
    "header_items_df = generate_header_set(items_df)\n",
    "\n",
    "# add headerID to items_df (drop before join if already existent)\n",
    "if 'headerID' in items_df.columns:\n",
    "    items_df = items_df.drop(columns=['headerID'])\n",
    "items_df = items_df.merge(header_items_df[['title','headerID']], left_on='title', right_on='title',how='left') \n",
    "display(items_df.head())\n",
    "print(f'missing headerIDs in items_df: {items_df[\"headerID\"].isnull().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language flag\n",
    "\n",
    "__Idea:__\n",
    "Flag Language of title in order to improve same language recommendations\n",
    "\n",
    "__Lookup Links:__\n",
    "1. [stackoverflow:](https://stackoverflow.com/questions/39142778/python-how-to-determine-the-language) comparison of different language detection modules\n",
    "2. [tds](https://towardsdatascience.com/benchmarking-language-detection-for-nlp-8250ea8b67c) performance evaluation -> recommends __fasttext__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define test strings\n",
    "str_en = \"romeo and juliet: the graphic novel\"\n",
    "str_de = \"sternenschweif. zauberhafter schulanfang\"\n",
    "\n",
    "# define whether to use existing flags and df\n",
    "if not recompute_lg_flg:\n",
    "    items_df = items_df_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### module testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# module detector dict\n",
    "lan_detector = {'ld': 'langdetect', 'gl': 'guess_language', 'lg': 'langid'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### langdetect (=title_ld)\n",
    "[langdetect](https://pypi.org/project/langdetect/)\n",
    "- important: use try-catch block to handle e.g. numerics, urls etc\n",
    "- non-deterministic approach: remember to set seed for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langdetect import DetectorFactory, detect\n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test detector on sample strings\n",
    "print(detect(str_en))\n",
    "print(detect(str_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if recompute_lg_flg:\n",
    "    # get start time for performance evaluation\n",
    "    start_time_ld = time.time()\n",
    "\n",
    "    # set seed for reproducability\n",
    "    DetectorFactory.seed = 0\n",
    "\n",
    "    # option 1: pre-calculate list of languages\n",
    "    title_ld = []\n",
    "    for title in items_df['title']:\n",
    "        try:\n",
    "            title_ld.append(detect(title))\n",
    "    #         print(f'{title}: {detect(title)}')\n",
    "        except LangDetectException:\n",
    "            title_ld.append(None)\n",
    "    #         print(f'{title}: \"undefined\"')\n",
    "\n",
    "    # compute execution time\n",
    "    end_time_ld = time.time()\n",
    "    print(f'exection time langdetect: {end_time_ld - start_time_ld} seconds')\n",
    "\n",
    "    items_df['title_ld'] = title_ld\n",
    "\n",
    "    # option 2: use apply and title col\n",
    "    # items_df['title_ld'] = items_df['title'].apply(lambda x: detect(x) if not x.isnumeric() else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# inspect items w/o language specification -> only numeric !\n",
    "print(f'cnt of items without language flag: {items_df[\"title_ld\"].isnull().sum()}')\n",
    "display(items_df[items_df[\"title_ld\"].isnull()].head(10))\n",
    "\n",
    "# inspect results\n",
    "ld_vc = pd.DataFrame(items_df['title_ld'].value_counts().reset_index())\n",
    "display(ld_vc.transpose())\n",
    "\n",
    "# show barplot with # items with title in given language\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.barplot(x='index', y='title_ld', ax=ax, data=ld_vc, palette=palette_blue).set(\n",
    "    xlabel='languages determined by \"langdetect\"',\n",
    "    ylabel='# items with title in given language'\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### guess_language (=title_gl)\n",
    "\n",
    "- Can detect very short samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from guess_language import guess_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(guess_language(str_en))\n",
    "print(guess_language(str_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if recompute_lg_flg:\n",
    "\n",
    "    # get start time for performance evaluation\n",
    "    start_time_gl = time.time()\n",
    "\n",
    "    # detect langauge of titles\n",
    "    items_df['title_gl'] = items_df['title'].apply(lambda x: guess_language(x) if not x.isnumeric() else None)\n",
    "\n",
    "    # set 'UNKNOWN' to None\n",
    "    items_df.loc[items_df['title_gl']=='UNKNOWN','title_gl'] = None\n",
    "\n",
    "    # compute execution time\n",
    "    end_time_gl = time.time()\n",
    "    print(f'exection time guess_language: {end_time_gl - start_time_gl} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# inspect results\n",
    "gl_vc = pd.DataFrame(items_df['title_gl'].value_counts().reset_index())\n",
    "display(gl_vc.transpose())\n",
    "\n",
    "# show barplot with # items with title in given language\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.barplot(x='index', y='title_gl', ax=ax, data=gl_vc, palette=palette_blue).set(\n",
    "    xlabel='languages determined by \"guess_language\"',\n",
    "    ylabel='# items with title in given language'\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### textblob\n",
    "Requires NLTK package, uses Google -> API blocked with \"HTTP Error 429: Too Many Requests\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.exceptions import TranslatorError"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(TextBlob(str_en).detect_language())\n",
    "print(TextBlob(str_de).detect_language())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get start time for performance evaluation\n",
    "start_time_tb = time.time()\n",
    "\n",
    "# option 1: pre-calculate list of languages\n",
    "title_tb = []\n",
    "\n",
    "for title in items_df['title']:\n",
    "    try:\n",
    "#         title_tb.append(detect(title))\n",
    "        print(f'{title}: {TextBlob(title).detect_language()}')\n",
    "    except TranslatorError as te:\n",
    "#         title_tb.append(None)\n",
    "        print(f'{title}: {te}')\n",
    "\n",
    "items_df['title_tb'] = title_tb\n",
    "\n",
    "# option 2: use apply\n",
    "# items_df['title_tb'] = items_df['title'].apply(lambda x: TextBlob(x).detect_language() if not x.isnumeric() or  else None)\n",
    "\n",
    "# compute execution time\n",
    "end_time_tb = time.time()\n",
    "print(f'exection time langdetect: {end_time_tb - start_time_tb} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### spacy\n",
    "- [spacy doku](https://spacy.io/universe/project/spacy-langdetect): did not get it working"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### langid (=title_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "langid.classify(str_en)\n",
    "langid.classify(str_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if recompute_lg_flg:\n",
    "\n",
    "    # get start time for performance evaluation\n",
    "    start_time_lg = time.time()\n",
    "\n",
    "    # option 1: pre-calculate list of languages\n",
    "    title_lg = []\n",
    "\n",
    "    for title in items_df['title']:\n",
    "        title_lg.append(langid.classify(title))\n",
    "        print(f'{title}: {langid.classify(title)}')\n",
    "\n",
    "    # compute execution time\n",
    "    end_time_lg = time.time()\n",
    "    print(f'exection time langid: {end_time_lg - start_time_lg} seconds')\n",
    "\n",
    "    # add col to df\n",
    "    items_df['title_lg'] = [t[0] for t in title_lg]\n",
    "\n",
    "    # option 2: use apply\n",
    "    # items_df['title_lg'] = items_df['title'].apply(lambda x: TextBlob(x).detect_language() if not x.isnumeric() or  else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# inspect items w/o language specification -> only numeric !\n",
    "print(f'cnt of items without language flag: {items_df[\"title_lg\"].isnull().sum()}')\n",
    "#display(items_df[items_df[\"title_lg\"].isnull()].head(10))\n",
    "\n",
    "# inspect results\n",
    "lg_vc = pd.DataFrame(items_df['title_lg'].value_counts().reset_index())\n",
    "display(lg_vc.transpose())\n",
    "\n",
    "# show barplot with # items with title in given language\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.barplot(x='index', y='title_lg', ax=ax, data=lg_vc, palette=palette_blue).set(\n",
    "    xlabel='languages determined by \"langid\"',\n",
    "    ylabel='# items with title in given language'\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fasttext\n",
    "- official Python binding module by Facebook\n",
    "- problems with installation on windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### module performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compare execution time and items w/o flag\n",
    "if recompute_lg_flg:\n",
    "    lan_detector_eval_df = pd.DataFrame({'execution time [s]': [eval('end_time_'+det.split(\"_\")[1]) - eval('start_time_'+det.split(\"_\")[1]) for det in ['title_ld','title_gl','title_lg']],\n",
    "                                        '#items w/o language flg':[items_df[det].isnull().sum() for det in ['title_ld','title_gl','title_lg']]},\n",
    "                                       index=[det for det in lan_detector.values()])\n",
    "    display(lan_detector_eval_df)\n",
    "\n",
    "# merge results dfs\n",
    "ld_gl_vc = ld_vc.merge(gl_vc, left_on='index', right_on='index', how='outer')\n",
    "ld_gl_lg_vc = ld_gl_vc.merge(lg_vc, left_on='index', right_on='index', how='outer')\n",
    "display(ld_gl_lg_vc.transpose())\n",
    "ld_gl_lg_vc = ld_gl_lg_vc.head(10)\n",
    "\n",
    "# rename columns\n",
    "ld_gl_lg_vc.columns = ['index', 'langdetect','guess_language','langid']\n",
    "\n",
    "# add language name\n",
    "ld_gl_lg_vc['language_name'] = ld_gl_lg_vc['index'].apply(lambda l: pycountry.countries.get(alpha_2=l).name if l != 'en' else 'English')\n",
    "\n",
    "# transform model cols into identifier column for plotting\n",
    "ld_gl_lg_vc = pd.melt(ld_gl_lg_vc, id_vars=[\"index\", \"language_name\"],\n",
    "                  var_name=\"flag_m\", value_name=\"idCnt\")\n",
    "#display(ld_gl_lg_vc)\n",
    "\n",
    "# Draw a nested barplot by language detector\n",
    "sns.set_theme()\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "g = sns.barplot(y=\"language_name\", x=\"idCnt\", hue=\"flag_m\", data=ld_gl_lg_vc, palette=palette_blue, orient='h')\n",
    "g.set(xlabel=\"# itemID\", ylabel = \"\")\n",
    "g.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [DEV] Topic Similarity\n",
    "__TODO: add scraping results of Estelle__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export of final pre-processed dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# export items_df\n",
    "# items_df.to_csv(items_path_pp)\n",
    "\n",
    "# export header_items_df\n",
    "# header_items_df.to_csv(header_items_path_pp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
