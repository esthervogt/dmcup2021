{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "657316a6",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "427bab2e",
   "metadata": {},
   "source": [
    "# Author: Esther Vogt\n",
    "# Creation Date: 18.04.2021\n",
    "# Purpose: Get a first understanding of the task & corresponding data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0dd54f",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6359a11",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Imports & Settings\n",
    "########################################################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1686534",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# allow display of all rows (with scrollbar)\n",
    "pd.set_option(\"display.max_rows\", 10) #pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# determine whether to use calculated language flags or recompute them\n",
    "recompute_lg_flg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4038dfe8",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Global Variables\n",
    "########################################################################################################################\n",
    "\n",
    "# change working dir to access tempData folder\n",
    "if os.getcwd().endswith('Data Understanding'):\n",
    "    os.chdir('..')\n",
    "    print(f'went one level up --> current workdir: {os.getcwd()}')\n",
    "\n",
    "# source data file paths\n",
    "transactions_path = '../data/external/transactions.csv'\n",
    "evaluation_path = '../data/external/evaluation.csv'\n",
    "items_path = '../data/external/items.csv'\n",
    "subject_cats_0_path = '../data/external/subject_cats_0.csv'\n",
    "\n",
    "# pre-processed data file paths (incl. language flags)\n",
    "items_path_pp = '../data/processed/items_pp.csv'\n",
    "\n",
    "# seaborn color palette\n",
    "palette_blue = \"Blues_d\"\n",
    "dark_blue = \"#011f4b\"\n",
    "middle_blue = \"#005b96\"\n",
    "light_blue = \"#b3cde0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce32192",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Functions\n",
    "########################################################################################################################\n",
    "\n",
    "def clean_alt_list(list_):\n",
    "    list_ = list_.replace(', ', ',')\n",
    "    list_ = list_.replace(',', ',')\n",
    "    list_ = list_.replace('[', '')\n",
    "    list_ = list_.replace(']', '')\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ad9136",
   "metadata": {},
   "source": [
    "## Data load & initial pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc42198",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Load Data & Print first summary statistics\n",
    "########################################################################################################################\n",
    "\n",
    "# Load the dmc source data\n",
    "# - clicks/baskets/order over a period of 3M\n",
    "# - rows: one transaction for single item\n",
    "transactions_df = pd.read_csv(transactions_path, delimiter='|', sep='.', encoding='utf-8')\n",
    "# - list of product ids (subset of products from items_df) to be used for prediction\n",
    "evaluation_df = pd.read_csv(evaluation_path, sep='.', encoding='utf-8')\n",
    "items_df = pd.read_csv(items_path, delimiter='|', sep='.', encoding='utf-8')\n",
    "\n",
    "# load category lookup table (manually created)\n",
    "subject_cats_0 = pd.read_csv(subject_cats_0_path, delimiter=';', encoding='utf-8')\n",
    "\n",
    "# Load pre-processed df (incl. language flags)\n",
    "items_df_pp = pd.read_csv(items_path_pp, delimiter=',', encoding='utf-8')\n",
    "\n",
    "# Print description of dfs\n",
    "\n",
    "# Get shape of dfs\n",
    "print(f'shape transactions_df: {transactions_df.shape}')\n",
    "#print(f'shape evaluation_df: {evaluation_df.shape}')\n",
    "print(f'shape items_df: {items_df.shape}\\n')\n",
    "\n",
    "# Get col names + datatype\n",
    "print(f'cols transactions_df: \\n{transactions_df.dtypes}\\n')\n",
    "#print(f'cols evaluation_df: \\n{evaluation_df.dtypes}\\n')\n",
    "print(f'cols items_df: \\n{items_df.dtypes}\\n')\n",
    "\n",
    "# Get description of dfs\n",
    "print(f'desc transactions_df: \\n{transactions_df.describe()}\\n')\n",
    "#print(f'desc evaluation_df: \\n{evaluation_df.describe()}\\n')\n",
    "print(f'desc items_df: \\n{items_df.describe()}\\n')\n",
    "\n",
    "# Get cnt of unique sessions / items\n",
    "print(f'cnt unqiue sessions: {transactions_df[\"sessionID\"].nunique()}') #271,983\n",
    "print(f'cnt unqiue items: {transactions_df[\"itemID\"].nunique()}') #24,909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a60fc1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Preprocessing for further inspection\n",
    "########################################################################################################################\n",
    "\n",
    "# extract list of base cols \n",
    "initial_cols= list(items_df.columns)\n",
    "\n",
    "# normalization: author col\n",
    "items_df.loc[items_df['author'] == 'ohne Autor', 'author'] = None\n",
    "\n",
    "# add col: get len of mt string\n",
    "items_df['mt_len'] = items_df['main topic'].str.len()\n",
    "\n",
    "# add col: get first element (top level category) of mt string\n",
    "items_df['mt_0'] = items_df['main topic'].str[0]\n",
    "\n",
    "# adjust subtopics: set to None if subtopics list is empty\n",
    "items_df['subtopics_str'] = items_df['subtopics'].astype(str).apply(clean_alt_list)\n",
    "items_df.loc[items_df['subtopics_str'].apply(len) ==0, 'subtopics_str'] = None\n",
    "\n",
    "# add col: get click / basket / order flag\n",
    "transactions_df['click_flg'] = np.where(transactions_df['click'] > 0, 1, 0)\n",
    "transactions_df['basket_flg'] = np.where(transactions_df['basket'] > 0, 1, 0)\n",
    "transactions_df['order_flg'] = np.where(transactions_df['order'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d0988",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# show dfs after initial pre-processing\n",
    "print(f'items_df after first pre-processing:')\n",
    "display(items_df.head(2))\n",
    "\n",
    "print(f'transactions_df after first pre-processing:')\n",
    "display(transactions_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b41c07e",
   "metadata": {},
   "source": [
    "## Overview statistics per relation / attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b803d8b",
   "metadata": {},
   "source": [
    "### items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc8cf04",
   "metadata": {},
   "source": [
    "#### author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd5bd9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# count of books per author\n",
    "books_per_author = pd.DataFrame.from_dict(Counter(items_df.loc[:,'author']),\n",
    "                                    orient='index',\n",
    "                                    columns=['book_cnt']).sort_values(by='book_cnt', ascending=False)\n",
    "books_per_author['frac[%]'] = books_per_author['book_cnt'] * 100 / books_per_author['book_cnt'].sum()\n",
    "\n",
    "print(f'# books per author:')\n",
    "display(books_per_author.head(10))\n",
    "\n",
    "print(f'summary statistics of books per author:')\n",
    "display(books_per_author.describe())\n",
    "\n",
    "# distribution of cnt af books among authors\n",
    "books_per_author_cnts = pd.DataFrame(books_per_author['book_cnt'].value_counts().reset_index()).rename(columns={'index': 'book_cnt', \n",
    "                                                                                                                'book_cnt': 'author_cnt'})\n",
    "books_per_author_cnts['author_cnt.cum'] = books_per_author_cnts['author_cnt'].cumsum()\n",
    "books_per_author_cnts['frac[%]'] = books_per_author_cnts['author_cnt'] * 100 / books_per_author_cnts['author_cnt'].sum()\n",
    "books_per_author_cnts['frac.cum[%]'] = books_per_author_cnts['frac[%]'].cumsum()\n",
    "\n",
    "print(f'distribution of books per author:')\n",
    "display(books_per_author_cnts.head(10))\n",
    "sns.set_theme()\n",
    "sns.histplot(books_per_author[books_per_author['book_cnt']<50]['book_cnt'], binwidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190feb5",
   "metadata": {},
   "source": [
    "#### publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003fa335",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# count of books per publisher\n",
    "books_per_publisher = pd.DataFrame.from_dict(Counter(items_df.loc[:,'publisher']),\n",
    "                                    orient='index',\n",
    "                                    columns=['book_cnt']).sort_values(by='book_cnt', ascending=False)\n",
    "books_per_publisher['frac[%]'] = books_per_publisher['book_cnt'] * 100 / books_per_publisher['book_cnt'].sum()\n",
    "\n",
    "print(f'# books per publisher:')\n",
    "display(books_per_publisher.head(10))\n",
    "\n",
    "print(f'summary statistics of books per publisher:')\n",
    "display(books_per_publisher.describe())\n",
    "\n",
    "# distribution of cnt af books among publishers\n",
    "books_per_publisher_cnts = pd.DataFrame(books_per_publisher['book_cnt'].value_counts().reset_index()).rename(columns={'index': 'book_cnt', \n",
    "                                                                                                                'book_cnt': 'publisher_cnt'})\n",
    "books_per_publisher_cnts['publisher_cnt.cum'] = books_per_publisher_cnts['publisher_cnt'].cumsum()\n",
    "books_per_publisher_cnts['frac[%]'] = books_per_publisher_cnts['publisher_cnt'] * 100 / books_per_publisher_cnts['publisher_cnt'].sum()\n",
    "books_per_publisher_cnts['frac.cum[%]'] = books_per_publisher_cnts['frac[%]'].cumsum()\n",
    "\n",
    "print(f'distribution of books per publisher:')\n",
    "display(books_per_publisher_cnts.head(10))\n",
    "sns.set_theme()\n",
    "sns.histplot(books_per_publisher[books_per_publisher['book_cnt']<50]['book_cnt'], binwidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2551d118",
   "metadata": {},
   "source": [
    "#### main topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c085c9d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# get depth of main topic tree\n",
    "print(f'str len main topics:')\n",
    "display(pd.DataFrame(items_df[\"mt_len\"].describe()))\n",
    "mt_len_hist = sns.histplot(items_df['mt_len']).set_title(f'distribution of len of main topics')\n",
    "\n",
    "# count of books per main topic (=mt) combo\n",
    "books_per_mt = pd.DataFrame.from_dict(Counter(items_df.loc[:,'main topic']),\n",
    "                                    orient='index',\n",
    "                                    columns=['book_cnt']).sort_values(by='book_cnt', ascending=False)\n",
    "books_per_mt['frac[%]'] = books_per_mt['book_cnt'] * 100 / books_per_mt['book_cnt'].sum()\n",
    "\n",
    "# plot mt_0 distribution\n",
    "sns.set_theme()\n",
    "sns.histplot(items_df['mt_0'].astype(str).sort_values())\n",
    "\n",
    "# count of books per first element of mt\n",
    "books_per_mt_0 = pd.DataFrame.from_dict(Counter(items_df.loc[:,'mt_0']),\n",
    "                                    orient='index',\n",
    "                                    columns=['book_cnt']).sort_values(by='book_cnt', ascending=False).reset_index()\n",
    "books_per_mt_0 = books_per_mt_0.rename(columns={'index': 'Notation'})\n",
    "books_per_mt_0['frac[%]'] = books_per_mt_0['book_cnt'] * 100 / books_per_mt_0['book_cnt'].sum()\n",
    "\n",
    "# join with category heading\n",
    "books_per_mt_0 = books_per_mt_0.merge(subject_cats_0, on='Notation', how='left')\n",
    "print(f'top 5 high level cats:')\n",
    "display(books_per_mt_0.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8955d",
   "metadata": {},
   "source": [
    "### transactions\n",
    "\n",
    "- basket: items that were added to basket but not necessarily bought\n",
    "- order: items that where finally bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge transactions with items to get title\n",
    "transactions_df = transactions_df.merge(items_df[['itemID','title']], left_on='itemID', right_on='itemID', how='left')\n",
    "transactions_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f690a",
   "metadata": {},
   "source": [
    "#### cnts per sessionID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0a959",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # get cnt of distinct item clicks per session\n",
    "# unique_clicks_per_session = transactions_df[['sessionID', 'click_flg']].groupby('sessionID')['click_flg'].sum().reset_index().\\\n",
    "#     sort_values(by='click_flg', ascending=False)\n",
    "# unique_clicks_per_session['frac[%]'] = unique_clicks_per_session['click_flg'] * 100 / unique_clicks_per_session['click_flg'].sum()\n",
    "# unique_clicks_per_session = unique_clicks_per_session.rename(columns={'click_flg': '#clicked items unique'})\n",
    "\n",
    "# print(f'clicked items per session:')\n",
    "# display(round(unique_clicks_per_session.head(10),2))\n",
    "\n",
    "# print(f'clicks per item summary stats:')\n",
    "# display(round(unique_clicks_per_session.describe(),2))\n",
    "\n",
    "# sns.boxplot(x=unique_clicks_per_session[\"#clicked items unique\"])\n",
    "# plt.show()\n",
    "\n",
    "# # get cnt of distinctly ordered items per session\n",
    "# orders_per_session = transactions_df[['sessionID', 'order_flg']].groupby('sessionID')['order_flg'].sum().reset_index().\\\n",
    "#     sort_values(by='order_flg', ascending=False).rename(columns={'order_flg': 'order_cnt'})\n",
    "# orders_per_session['frac[%]'] = orders_per_session['order_cnt'] * 100 / orders_per_session['order_cnt'].sum()\n",
    "\n",
    "# print(f'distinct orders per session (binary, w/o qty):')\n",
    "# display(orders_per_session.head(10))\n",
    "\n",
    "# print(f'distinct orders per session summary stats:')\n",
    "# display(orders_per_session.describe())\n",
    "\n",
    "# sns.boxplot(x=orders_per_session[\"order_cnt\"])\n",
    "# plt.show()\n",
    "\n",
    "# # get cnt of distinct order sessions per item\n",
    "# orders_per_item = transactions_df[['itemID', 'order_flg']].groupby('itemID')['order_flg'].sum().reset_index().\\\n",
    "#     sort_values(by='order_flg', ascending=False).rename(columns={'order_flg': 'order_cnt'})\n",
    "# orders_per_item['frac[%]'] = orders_per_item['order_cnt'] * 100 / orders_per_item['order_cnt'].sum()\n",
    "\n",
    "# # print(f'distinct orders per item (binary, w/o qty):')\n",
    "# # display(orders_per_item.head(10))\n",
    "\n",
    "# print(f'distinct orders per item summary stats:')\n",
    "# display(orders_per_item.describe())\n",
    "\n",
    "# get cnt of distinct orders / basket /orders per session\n",
    "interaction_per_session = transactions_df[['sessionID', \n",
    "                                           'click_flg',\n",
    "                                           'basket_flg',\n",
    "                                           'order_flg']].groupby('sessionID').sum().reset_index()\n",
    "print(f'distribution of unique items clicked, added to basket, ordered:')\n",
    "display(round(interaction_per_session[['click_flg','basket_flg','order_flg']].describe(),1).loc[['count','mean','std','25%','50%','75%','max']])\n",
    "\n",
    "# get click to basket to order conversion\n",
    "items_per_basket_order = transactions_df[['itemID',\n",
    "                                          'click_flg',\n",
    "                                          'basket_flg',\n",
    "                                          'order_flg']].groupby(['click_flg',\n",
    "                                                                 'basket_flg',\n",
    "                                                                 'order_flg'])['itemID'].count().reset_index().rename(columns={'itemID': 'item_cnt'})\n",
    "items_per_basket_order['frac[%]'] = items_per_basket_order['item_cnt'] * 100 / items_per_basket_order['item_cnt'].sum()\n",
    "print(f'click to basket to order conversion:')\n",
    "display(round(items_per_basket_order.sort_values(by=['click_flg','basket_flg','order_flg'],ascending=False),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553eaa7e",
   "metadata": {},
   "source": [
    "#### top interaction items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef2cdc",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# get top sellers\n",
    "top_interaction_items = transactions_df[['itemID', 'title',\n",
    "                                         'click', \n",
    "                                         'basket', \n",
    "                                         'order']].groupby(['itemID','title']).sum().reset_index().sort_values(by='click')\n",
    "top_clicked_items = top_interaction_items.sort_values(by='click',ascending=False).head(5)\n",
    "top_basket_items = top_interaction_items.sort_values(by='basket',ascending=False).head(5)\n",
    "top_order_items = top_interaction_items.sort_values(by='order',ascending=False).head(5)\n",
    "# display(top_interaction_items.head(10))\n",
    "\n",
    "# generate barplot\n",
    "sns.set_theme()\n",
    "fig, ax = plt.subplots(3,1)\n",
    "plt.tight_layout()\n",
    "sns.barplot(data=top_clicked_items,x='click',y='title',palette=palette_blue, ax=ax[0]).set(xlabel=\"# clicks\",ylabel=\"\")\n",
    "sns.barplot(data=top_basket_items,x='basket',y='title',palette=palette_blue, ax=ax[1]).set(xlabel=\"# added to basket\",ylabel=\"\")\n",
    "sns.barplot(data=top_order_items,x='order',y='title',palette=palette_blue, ax=ax[2]).set(xlabel=\"# orders\",ylabel=\"\")\n",
    "plt.show()\n",
    "\n",
    "# # get cnt of clicks per item\n",
    "# clicks_per_item = transactions_df[['itemID', 'click']].groupby('itemID')['click'].sum().reset_index().\\\n",
    "#     sort_values(by='click', ascending=False).rename(columns={'click': 'click_cnt'})\n",
    "# clicks_per_item['frac[%]'] = clicks_per_item['click_cnt'] * 100 / clicks_per_item['click_cnt'].sum()\n",
    "\n",
    "# print(f'clicks per item:')\n",
    "# display(clicks_per_item.head(10))\n",
    "\n",
    "# print(f'clicks per item summary stats:')\n",
    "# display(clicks_per_item.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580451a3",
   "metadata": {},
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505931a",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "- 9 items w/o publisher: \n",
    "    - could be anything, cannot be imputed\n",
    "    - not such a crucial information to be missing\n",
    "    - thus: no handling \n",
    "- 3240 items w/o author:\n",
    "    - correct author might not be uniquely determinable or there might not even be a senseful author\n",
    "    - thus: no handling\n",
    "- 258 items w/o main topic:\n",
    "    - at least subtopic is given\n",
    "    - only 32 of these also have the author missing\n",
    "- 36,904 items w/o subtopic:\n",
    "    - in all of the cases, a main topic is given \n",
    "    - thus: still enough information available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca0023",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# get cnt of missing values per column\n",
    "missing_values = pd.DataFrame(items_df.isnull().sum()).rename(columns={0: 'cnt'})\n",
    "missing_values['frac[%]'] = missing_values['cnt'] * 100 / len(items_df)\n",
    "print(f'null values per column:')\n",
    "display(round(missing_values.loc[initial_cols + [\"subtopics_str\"]],2))\n",
    "\n",
    "# get cnt of combined null values: sum null values per row and cnt rows with #null > 1\n",
    "print(f'\\n# rows with null values in more than one col: {(items_df[initial_cols + [\"subtopics_str\"]].isnull().sum(axis=1) > 1).sum()}')\n",
    "print(f'\\ndistribution of null values over cols (1=null, 0=not null):')\n",
    "display(pd.DataFrame((items_df[initial_cols + ['subtopics_str']].isnull() * 1).value_counts().reset_index()).rename(columns={0: '#items'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc67e53",
   "metadata": {},
   "source": [
    "#### Missing publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18bec6",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# check all items with missing publisher\n",
    "print('all items with missing publisher:')\n",
    "display(items_df[items_df['publisher'].isnull()])\n",
    "\n",
    "# check whether there might be other entries with publisher given\n",
    "missing_publisher_title = items_df[items_df['publisher'].isnull()]['title']\n",
    "print(f'books with same title that appear twice: {(items_df[items_df[\"title\"].isin(missing_publisher_title)].groupby(\"title\")[\"itemID\"].count() > 1).sum()}\\n')\n",
    "\n",
    "# inspect sample with missing publisher \n",
    "# > missing publisher is most likely to be 'TEKTIME' > however: could also be different\n",
    "print('entries for title \"Back to Earth\" with missing publisher for some editions:')\n",
    "display(items_df[items_df['title'].str.contains('Back to Earth')])\n",
    "print('entries for author \"Danilo Clementoni\" with missing publisher for some items:')\n",
    "display(items_df[items_df['author'] == 'Danilo Clementoni'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d217beb",
   "metadata": {},
   "source": [
    "#### Missing author\n",
    "- __problem__: \n",
    "    - there is a lot of items with very generalistic titles like 'Dinosaurier' or 'Die Weihnachtsgeschichte' that do not allow to uniquely determine the correct author\n",
    "    - there might not even be a unique author, like for 'Freundebuch - Einhorn-Paradies - Meine Freunde' or 'Kritzkratz-Spaß Glitzer'\n",
    "    - there might be the same item but several different authors, like for 'Goldilocks and the Three Bears'\n",
    "    \n",
    "- __approach__: \n",
    "    - try to not impute author, use other attributes instead, e.g. topic or publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0786d088",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# check all items with missing author\n",
    "print('first 10 items with missing author:')\n",
    "display(items_df[items_df['author'].isnull()].head(10))\n",
    "\n",
    "# check whether there might be other entries with author given\n",
    "missing_author_title = items_df[items_df['author'].isnull()]['title']\n",
    "missing_author_cnt_dups = pd.DataFrame(items_df[items_df[\"title\"].isin(missing_author_title)].groupby(\"title\")[\"itemID\"].count())\n",
    "print(f'\\nbooks with same title that appear twice (see df below): {(missing_author_cnt_dups[\"itemID\"] > 1).sum()}')\n",
    "\n",
    "# check whether author can be retried\n",
    "missing_author_dups = missing_author_cnt_dups[missing_author_cnt_dups[\"itemID\"] > 1].reset_index()['title']\n",
    "display(items_df[items_df['title'].isin(missing_author_dups)].sort_values(by='title'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b61623",
   "metadata": {},
   "source": [
    "#### Missing topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631db1f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# check whether there are items with no topic at all\n",
    "print(f'cnt of items with both, main topic and subtopic == null: {((items_df[\"subtopics_str\"].isnull()) & (items_df[\"main topic\"].isnull())).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cf2440",
   "metadata": {},
   "source": [
    "##### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb4113",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check all items with missing topic\n",
    "print('first 10 items with missing topic:')\n",
    "display(items_df[items_df['main topic'].isnull()].head(10))\n",
    "\n",
    "# check whether there might be other entries with topic given\n",
    "missing_topic_title = items_df[items_df['main topic'].isnull()]['title']\n",
    "missing_topic_cnt_dups = pd.DataFrame(items_df[items_df[\"title\"].isin(missing_topic_title)].groupby(\"title\")[\"itemID\"].count())\n",
    "print(f'\\nbooks with same title that appear twice (see df below): {(missing_topic_cnt_dups[\"itemID\"] > 1).sum()}')\n",
    "\n",
    "# check whether topic can be retried\n",
    "missing_topic_dups = missing_topic_cnt_dups[missing_topic_cnt_dups[\"itemID\"] > 1].reset_index()['title']\n",
    "display(items_df[items_df['title'].isin(missing_topic_dups)].sort_values(by='title'))\n",
    "\n",
    "# check cnt of items with main topic and subtopic missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68309f2",
   "metadata": {},
   "source": [
    "##### sub\n",
    "- no scalable solution for imputing subtopics\n",
    "- out of the 36,904 missing subtopics, only 2,668 items appear multiple times\n",
    "    - out of these, only 1,574 actually have a duplicate with a subtopic given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291d94b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# check all items with missing topic\n",
    "print('first 10 items with missing topic:')\n",
    "display(items_df[items_df['subtopics_str'].isnull()])\n",
    "\n",
    "# check whether there might be other entries with topic given\n",
    "missing_topic_title = items_df[items_df['subtopics_str'].isnull()]['title']\n",
    "missing_topic_cnt_dups = pd.DataFrame(items_df[items_df[\"title\"].isin(missing_topic_title)].groupby(\"title\")[\"itemID\"].count())\n",
    "print(f'\\nbooks with same title that appear twice (see df below): {(missing_topic_cnt_dups[\"itemID\"] > 1).sum()}')\n",
    "\n",
    "# check whether topic can be retried\n",
    "missing_topic_dups = missing_topic_cnt_dups[(missing_topic_cnt_dups[\"itemID\"] > 1)].reset_index()['title']\n",
    "display(items_df[(items_df['title'].isin(missing_topic_dups)) & (~items_df['subtopics_str'].isnull())].sort_values(by='title'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873af8d",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "\n",
    "__To keep in mind:__\n",
    "1. other relevant attributes are not given, e.g.:\n",
    "    - actual __language__ might not be that of title\n",
    "    - __publication date__ might differ between itemIDs (=Neuauflage)\n",
    "    - title might not be complete (e.g. __subtitle__ missing)\n",
    "        - e.g. '[Ära der Lichtwächter](https://www.amazon.com/s?k=%C3%84ra+der+Lichtw%C3%A4chter&ref=nb_sb_noss)' from 'Klaus Pfrommer' (itemID = (40200,18242)) is collection with differing subtitles \"Die Täuschung\", \"Das Vermächtnis\", \"Die Unschuld\" \n",
    "    - thus: itemID would be unique identifier for actually different items\n",
    "2. __transactions__ might help to differentiate between items and __rank their relevance__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110503d2",
   "metadata": {},
   "source": [
    "#### duplicate entries per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4497c1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# cnt column-wise duplication\n",
    "sc_cnt = 1\n",
    "for col in initial_cols:\n",
    "    print(f'cnt of duplicate {col}: {(items_df[col].value_counts() > 1).sum()}')\n",
    "    \n",
    "# inspect title duplicates\n",
    "title_cnts = (items_df[\"title\"].value_counts().reset_index())\n",
    "title_dups_lst = title_cnts[title_cnts[\"title\"]>1][\"index\"]\n",
    "items_df[(items_df[\"title\"].isin(title_dups_lst))].sort_values(by=\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9f307",
   "metadata": {},
   "source": [
    "#### everything identical except of single column\n",
    "- only cases for duplicated items with same attributes but different itemID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c780cc",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "col_list = initial_cols #['itemID'] \n",
    "for col in col_list:\n",
    "    \n",
    "    # check all cols except of current one\n",
    "    col_list_lim = [c for c in items_df.columns if c != col]\n",
    "    #print(f'{col}: {col_list_lim}')\n",
    "\n",
    "    # compute duplicate cnt\n",
    "    dup = pd.DataFrame(items_df.groupby(col_list_lim)[col].count().reset_index())\n",
    "    print(f'everything identical except of {col} = {(dup[col] > 1).sum()}')\n",
    "    #display(dup[dup[col] > 1].sort_values(by=col))\n",
    "    #display(dup.sort_values(by=col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463b68c5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# deep dive: everything identical except of ID\n",
    "print(f'sample entry for sc1: everything identical except of itemID')\n",
    "display(items_df[items_df['title']=='Reisestipendien'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135fbe3c",
   "metadata": {},
   "source": [
    "### [DEV] Outlier Detection\n",
    "- only for __transactions__: remove transactions with suspiciously high #of clicks/basket/order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb473d6",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cda15bc",
   "metadata": {},
   "source": [
    "### [DEV] String normalization \n",
    "\n",
    "__Applied:__\n",
    "1. conversion to lowercase, e.g. publisher = 'TEKTIME' or 'Tektime' to 'tektime'\n",
    "2. removal of leading special characters, e.g. \",william shakespeare\" \n",
    "3. conversion of unicode characters (ä,ö,ü)\n",
    "\n",
    "__No fix yet:__\n",
    "1. author = 'V. S. Nesby' and 'Vs Nesby' -> approach: no test for equality but similarity / remove dots?\n",
    "2. weird entries\n",
    "    - author: der Authhhhor\n",
    "    - diverse Autoren, Autoren\n",
    "3. unicode characters like (à,é,è,°o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a76c70",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# generate copy of original df\n",
    "items_df_cl = items_df.copy()\n",
    "display(items_df_cl.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73073f8f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# remove leading non-alphanumerics, e.g. \",william shakespeare\"\n",
    "print(f'cnt of authors with leading non-alphanumerics (before normalization): {items_df_cl[\"author\"].str.startswith(\",\").sum()}')\n",
    "items_df_cl[\"author_cl\"] = items_df_cl[\"author\"].astype(str).apply(lambda x: re.sub(r'^\\W+', r'', x))\n",
    "print(f'cnt of authors with leading non-alphanumerics (after normalization): {items_df_cl[\"author_cl\"].str.startswith(\",\").sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac682f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# removal of other special characters: ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57192818",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# insert dot after single characters\n",
    "items_df_cl[\"author_cl\"] = items_df_cl[\"author_cl\"].astype(str).apply(lambda x: re.sub(r'([A-Z])\\.?(?![a-z])\\s*', r'\\g<1>. ', x))\n",
    "print(f'inserted dot after single capital letters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82239fe",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# convert all strings to lowercase\n",
    "items_df_cl = items_df_cl.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "#display(items_df_cl.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75644c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# convert umlaute\n",
    "chars = {'ö':'oe','ä':'ae','ü':'ue'} # usw.\n",
    "for char in chars:\n",
    "    items_df_cl[\"author_cl\"] = items_df_cl[\"author_cl\"].apply(lambda s: s.replace(char, chars[char]) if type(s) == str else s)\n",
    "    \n",
    "# test sample after normalization\n",
    "items_df_cl[items_df_cl[\"author_cl\"].str.contains('schlueter')].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c860d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# test effect of normalization\n",
    "\n",
    "# inspect overall df\n",
    "items_df_cl[~items_df_cl['author'].isna()].sort_values(by='author').head(100)[['itemID','title', 'author','author_cl']]\n",
    "\n",
    "# check items affected by normalization\n",
    "author_cl_unique_author = items_df_cl.groupby(\"author_cl\")[\"author\"].nunique()\n",
    "print(f'cnt of authors that could be matched due to normalization: {(author_cl_unique_author > 1).sum()}')\n",
    "items_df_cl[items_df_cl['author_cl'].isin(author_cl_unique_author[author_cl_unique_author > 1].reset_index()['author_cl'])].sort_values(by='author_cl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe3a19",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de54f822",
   "metadata": {},
   "source": [
    "### Language flag\n",
    "\n",
    "__Idea:__\n",
    "Flag Language of title in order to improve same language recommendations\n",
    "\n",
    "__Lookup Links:__\n",
    "1. [stackoverflow:](https://stackoverflow.com/questions/39142778/python-how-to-determine-the-language) comparison of different language detection modules\n",
    "2. [tds](https://towardsdatascience.com/benchmarking-language-detection-for-nlp-8250ea8b67c) performance evaluation -> recommends __fasttext__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053225a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# define test strings\n",
    "str_en = \"romeo and juliet: the graphic novel\"\n",
    "str_de = \"sternenschweif. zauberhafter schulanfang\"\n",
    "\n",
    "# define whether to use existing flags and df \n",
    "if not recompute_lg_flg:\n",
    "    items_df = items_df_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c42588",
   "metadata": {},
   "source": [
    "#### module testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e2a84",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# module detector dict\n",
    "lan_detector = {'ld': 'langdetect', 'gl': 'guess_language', 'lg': 'langid'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d954c62",
   "metadata": {},
   "source": [
    "##### langdetect (=title_ld)\n",
    "[langdetect](https://pypi.org/project/langdetect/)\n",
    "- important: use try-catch block to handle e.g. numerics, urls etc\n",
    "- non-deterministic approach: remember to set seed for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c9f845",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from langdetect import DetectorFactory, detect\n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558bbbd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# test detector on sample strings\n",
    "print(detect(str_en))\n",
    "print(detect(str_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30afb16",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if recompute_lg_flg:\n",
    "    # get start time for performance evaluation\n",
    "    start_time_ld = time.time() \n",
    "\n",
    "    # set seed for reproducability\n",
    "    DetectorFactory.seed = 0 \n",
    "\n",
    "    # option 1: pre-calculate list of languages\n",
    "    title_ld = []\n",
    "    for title in items_df['title']:\n",
    "        try: \n",
    "            title_ld.append(detect(title))\n",
    "    #         print(f'{title}: {detect(title)}')\n",
    "        except LangDetectException:\n",
    "            title_ld.append(None)\n",
    "    #         print(f'{title}: \"undefined\"')\n",
    "\n",
    "    # compute execution time\n",
    "    end_time_ld = time.time()\n",
    "    print(f'exection time langdetect: {end_time_ld - start_time_ld} seconds')\n",
    "\n",
    "    items_df['title_ld'] = title_ld\n",
    "\n",
    "    # option 2: use apply and title col\n",
    "    # items_df['title_ld'] = items_df['title'].apply(lambda x: detect(x) if not x.isnumeric() else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd01ef",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# inspect items w/o language specification -> only numeric !\n",
    "print(f'cnt of items without language flag: {items_df[\"title_ld\"].isnull().sum()}')\n",
    "display(items_df[items_df[\"title_ld\"].isnull()].head(10))\n",
    "\n",
    "# inspect results\n",
    "ld_vc = pd.DataFrame(items_df['title_ld'].value_counts().reset_index())\n",
    "display(ld_vc.transpose())\n",
    "\n",
    "# show barplot with # items with title in given language\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.barplot(x='index', y='title_ld', ax=ax, data=ld_vc, palette=palette_blue).set(\n",
    "    xlabel='languages determined by \"langdetect\"', \n",
    "    ylabel='# items with title in given language'\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df89d05",
   "metadata": {},
   "source": [
    "##### guess_language (=title_gl)\n",
    "\n",
    "- Can detect very short samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03861ea5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from guess_language import guess_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c275d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(guess_language(str_en))\n",
    "print(guess_language(str_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83b356",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if recompute_lg_flg:\n",
    "\n",
    "    # get start time for performance evaluation\n",
    "    start_time_gl = time.time() \n",
    "\n",
    "    # detect langauge of titles \n",
    "    items_df['title_gl'] = items_df['title'].apply(lambda x: guess_language(x) if not x.isnumeric() else None)\n",
    "\n",
    "    # set 'UNKNOWN' to None\n",
    "    items_df.loc[items_df['title_gl']=='UNKNOWN','title_gl'] = None\n",
    "\n",
    "    # compute execution time\n",
    "    end_time_gl = time.time()\n",
    "    print(f'exection time guess_language: {end_time_gl - start_time_gl} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9882b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect results\n",
    "gl_vc = pd.DataFrame(items_df['title_gl'].value_counts().reset_index())\n",
    "display(gl_vc.transpose())\n",
    "\n",
    "# show barplot with # items with title in given language\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.barplot(x='index', y='title_gl', ax=ax, data=gl_vc, palette=palette_blue).set(\n",
    "    xlabel='languages determined by \"guess_language\"', \n",
    "    ylabel='# items with title in given language'\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae130d",
   "metadata": {},
   "source": [
    "##### textblob\n",
    "Requires NLTK package, uses Google -> API blocked with \"HTTP Error 429: Too Many Requests\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "5aadaa24",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.exceptions import TranslatorError"
   ]
  },
  {
   "cell_type": "raw",
   "id": "937b2d10",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "print(TextBlob(str_en).detect_language())\n",
    "print(TextBlob(str_de).detect_language())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31492ce9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# get start time for performance evaluation\n",
    "start_time_tb = time.time() \n",
    "\n",
    "# option 1: pre-calculate list of languages\n",
    "title_tb = []\n",
    "\n",
    "for title in items_df['title']:\n",
    "    try: \n",
    "#         title_tb.append(detect(title))\n",
    "        print(f'{title}: {TextBlob(title).detect_language()}')\n",
    "    except TranslatorError as te:\n",
    "#         title_tb.append(None)\n",
    "        print(f'{title}: {te}')\n",
    "    \n",
    "items_df['title_tb'] = title_tb\n",
    "\n",
    "# option 2: use apply\n",
    "# items_df['title_tb'] = items_df['title'].apply(lambda x: TextBlob(x).detect_language() if not x.isnumeric() or  else None)\n",
    "\n",
    "# compute execution time\n",
    "end_time_tb = time.time()\n",
    "print(f'exection time langdetect: {end_time_tb - start_time_tb} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c646a1",
   "metadata": {},
   "source": [
    "##### spacy\n",
    "- [spacy doku](https://spacy.io/universe/project/spacy-langdetect): did not get it working"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf443c2f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6284f39",
   "metadata": {},
   "source": [
    "##### langid (=title_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3902be4a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed8d6c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "langid.classify(str_en)\n",
    "langid.classify(str_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21845bc7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if recompute_lg_flg:\n",
    "\n",
    "    # get start time for performance evaluation\n",
    "    start_time_lg = time.time() \n",
    "\n",
    "    # option 1: pre-calculate list of languages\n",
    "    title_lg = []\n",
    "\n",
    "    for title in items_df['title']:\n",
    "        title_lg.append(langid.classify(title))\n",
    "        print(f'{title}: {langid.classify(title)}')\n",
    "\n",
    "    # compute execution time\n",
    "    end_time_lg = time.time()\n",
    "    print(f'exection time langid: {end_time_lg - start_time_lg} seconds')\n",
    "\n",
    "    # add col to df\n",
    "    items_df['title_lg'] = [t[0] for t in title_lg]\n",
    "\n",
    "    # option 2: use apply\n",
    "    # items_df['title_lg'] = items_df['title'].apply(lambda x: TextBlob(x).detect_language() if not x.isnumeric() or  else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929ed70",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# inspect items w/o language specification -> only numeric !\n",
    "print(f'cnt of items without language flag: {items_df[\"title_lg\"].isnull().sum()}')\n",
    "#display(items_df[items_df[\"title_lg\"].isnull()].head(10))\n",
    "\n",
    "# inspect results\n",
    "lg_vc = pd.DataFrame(items_df['title_lg'].value_counts().reset_index())\n",
    "display(lg_vc.transpose())\n",
    "\n",
    "# show barplot with # items with title in given language\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "sns.barplot(x='index', y='title_lg', ax=ax, data=lg_vc, palette=palette_blue).set(\n",
    "    xlabel='languages determined by \"langid\"', \n",
    "    ylabel='# items with title in given language'\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef928f",
   "metadata": {},
   "source": [
    "##### fasttext\n",
    "- official Python binding module by Facebook\n",
    "- problems with installation on windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32f58c",
   "metadata": {},
   "source": [
    "### module performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3afe47",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# compare execution time and items w/o flag\n",
    "if recompute_lg_flg:\n",
    "    lan_detector_eval_df = pd.DataFrame({'execution time [s]': [eval('end_time_'+det.split(\"_\")[1]) - eval('start_time_'+det.split(\"_\")[1]) for det in ['title_ld','title_gl','title_lg']],\n",
    "                                        '#items w/o language flg':[items_df[det].isnull().sum() for det in ['title_ld','title_gl','title_lg']]},\n",
    "                                       index=[det for det in lan_detector.values()])\n",
    "    display(lan_detector_eval_df)\n",
    "\n",
    "# merge results dfs\n",
    "ld_gl_vc = ld_vc.merge(gl_vc, left_on='index', right_on='index', how='outer')\n",
    "ld_gl_lg_vc = ld_gl_vc.merge(lg_vc, left_on='index', right_on='index', how='outer')\n",
    "display(ld_gl_lg_vc.transpose())\n",
    "ld_gl_lg_vc = ld_gl_lg_vc.head(10)\n",
    "\n",
    "# rename columns\n",
    "ld_gl_lg_vc.columns = ['index', 'langdetect','guess_language','langid']\n",
    "\n",
    "# add language name\n",
    "ld_gl_lg_vc['language_name'] = ld_gl_lg_vc['index'].apply(lambda l: pycountry.countries.get(alpha_2=l).name if l != 'en' else 'English')\n",
    "\n",
    "# transform model cols into identifier column for plotting\n",
    "ld_gl_lg_vc = pd.melt(ld_gl_lg_vc, id_vars=[\"index\", \"language_name\"], \n",
    "                  var_name=\"flag_m\", value_name=\"idCnt\")\n",
    "#display(ld_gl_lg_vc)\n",
    "\n",
    "# Draw a nested barplot by language detector\n",
    "sns.set_theme()\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "g = sns.barplot(y=\"language_name\", x=\"idCnt\", hue=\"flag_m\", data=ld_gl_lg_vc, palette=palette_blue, orient='h')\n",
    "g.set(xlabel=\"# itemID\", ylabel = \"\")\n",
    "g.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2313093",
   "metadata": {},
   "source": [
    "### [DEV] Topic Similarity\n",
    "__TODO: add scraping results of Estelle__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8529bbf9",
   "metadata": {},
   "source": [
    "## Export of final pre-processed df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d0f276",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# print final df to .csv\n",
    "#items_df.to_csv(items_path_pp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}